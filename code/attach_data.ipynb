{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e076103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codeocean import CodeOcean\n",
    "from codeocean.data_asset import DataAssetSearchParams, DataAssetAttachParams\n",
    "from codeocean.components import SearchFilter\n",
    "import os\n",
    "from aind_dynamic_foraging_data_utils.code_ocean_utils import get_assets, attach_data, add_data_asset_path \n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from aind_dynamic_foraging_behavior_video_analysis.kinematics.tongue_kinematics_utils import get_session_name_from_path, plot_keypoint_confidence_analysis\n",
    "import glob\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a66b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2706b363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query matches: 11\n",
      "d330c095-44b6-43bf-bf8e-eaf435bea9e9 behavior_751181_2025-02-27_11-24-47_sorted_curated_2025-03-25_22-37-19\n",
      "9b285728-1647-49d7-83d7-309892cf1160 behavior_751181_2025-02-27_11-24-44_videoprocessed_2025-10-29_21-59-06\n",
      "ae5f98b1-f883-4615-825b-cfeb6a2ed43b behavior_751181_2025-02-27_11-24-44_videoprocessed_2025-10-24_21-43-19\n",
      "4f5c31bc-25fa-43ea-97d2-7ed63dad3b00 behavior_751181_2025-02-27_11-24-44_videoprocessed_2025-10-24_21-43-19\n",
      "2e3d9361-3347-48a4-9fac-e0180450db4b behavior_751181_2025-02-27_11-24-44_videoprocessed_2025-10-24_21-43-19\n",
      "ad853a27-d3fe-41fe-9d0b-ec26a418b329 behavior_751181_2025-02-27_11-24-44_videoprocessed_2025-09-09_18-59-42\n",
      "c5fbf157-805e-4d29-ba89-83a053545e22 behavior_751181_2025-02-27_11-24-44_sorted_2025-03-11_00-30-26\n",
      "ad291c3a-bf5e-4d03-af52-e59d0b183538 behavior_751181_2025-02-27_11-24-44_sorted-opto-bp_2025-03-21_01-06-52\n",
      "a701b4e0-9560-4e45-85b2-6b12187c0ab9 behavior_751181_2025-02-27_11-24-44_curated-ZhixiaoSu_2025-03-25_18-32-11\n",
      "12199fde-530b-4aca-beed-11cd37696483 behavior_751181_2025-02-27_11-24-44_clip_frame\n",
      "c3a218ea-bea0-4ba5-9a95-4b8353340cad behavior_751181_2025-02-27_11-24-44\n",
      "Attached most recent videoprocessed asset:\n",
      "  ID:   9b285728-1647-49d7-83d7-309892cf1160\n",
      "  Name: behavior_751181_2025-02-27_11-24-44_videoprocessed_2025-10-29_21-59-06\n",
      "  Time: 2025-10-29T21:59:06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "client = CodeOcean(domain=\"https://codeocean.allenneuraldynamics.org\",\n",
    "                   token=os.getenv(\"API_SECRET\"))\n",
    "\n",
    "needle = \"behavior_751181_2025-02-27\"\n",
    "\n",
    "# A) Free-text query (supports patterns like name:... per docs)\n",
    "params_query = DataAssetSearchParams(\n",
    "    offset=0, limit=100,\n",
    "    sort_order=\"desc\", sort_field=\"name\",\n",
    "    archived=False, favorite=False,\n",
    "    query=f\"name:{needle}\"\n",
    ")\n",
    "res_query = client.data_assets.search_data_assets(params_query)\n",
    "print(\"Query matches:\", len(res_query.results))\n",
    "for r in res_query.results:\n",
    "    print(r.id, r.name)\n",
    "\n",
    "\n",
    "# --- helper: pick most recent videoprocessed asset from a list of asset models ---\n",
    "def most_recent_videoprocessed_asset(assets):\n",
    "    \"\"\"\n",
    "    assets: iterable of DataAsset model objects with .name and .id\n",
    "    Returns: (asset, parsed_datetime) or (None, None) if none match\n",
    "    \"\"\"\n",
    "    pat = re.compile(r\"_videoprocessed_(\\d{4}-\\d{2}-\\d{2})_(\\d{2}-\\d{2}-\\d{2})\")\n",
    "    best = None\n",
    "    best_dt = None\n",
    "    for a in assets:\n",
    "        m = pat.search(a.name)\n",
    "        if not m:\n",
    "            continue\n",
    "        dt = datetime.strptime(f\"{m.group(1)}_{m.group(2)}\", \"%Y-%m-%d_%H-%M-%S\")\n",
    "        if (best_dt is None) or (dt > best_dt):\n",
    "            best_dt = dt\n",
    "            best = a\n",
    "    return best, best_dt\n",
    "\n",
    "# Filter the searched assets down to the ones with _videoprocessed_ timestamps\n",
    "videoprocessed_assets = [r for r in res_query.results if \"_videoprocessed_\" in r.name]\n",
    "\n",
    "latest_asset, latest_dt = most_recent_videoprocessed_asset(videoprocessed_assets)\n",
    "\n",
    "if latest_asset is None:\n",
    "    print(\"No videoprocessed assets found in search results.\")\n",
    "else:\n",
    "    # Choose a clear mount name (adjust to your convention if needed)\n",
    "    # ex: \"behavior_751181_2025-02-27_videoprocessed\"\n",
    "    # mount_name = f\"{needle}_videoprocessed\"\n",
    "    mount_name = latest_asset.mount\n",
    "\n",
    "    # Attach\n",
    "    attach_params = [DataAssetAttachParams(id=latest_asset.id, mount=mount_name)]\n",
    "    results = client.capsules.attach_data_assets(\n",
    "        capsule_id=os.getenv(\"CO_CAPSULE_ID\"),\n",
    "        attach_params=attach_params,\n",
    "    )\n",
    "\n",
    "    print(f\"Attached most recent videoprocessed asset:\")\n",
    "    print(f\"  ID:   {latest_asset.id}\")\n",
    "    print(f\"  Name: {latest_asset.name}\")\n",
    "    print(f\"  Time: {latest_dt.isoformat()}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aba53ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No predictions.csv files found for behavior_717121_2024-06-15_10-00-58\n",
      "⚠️ No predictions.csv files found for behavior_781166_2025-05-13_14-04-27\n",
      "⚠️ No predictions.csv files found for behavior_781166_2025-05-14_14-18-28\n",
      "⚠️ No predictions.csv files found for behavior_781166_2025-05-15_14-20-51\n",
      "pred_csv_list = [\n",
      "    \"/root/capsule/data/behavior_716325_2024-05-31_10-31-14_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_717259_2024-06-28_11-17-19_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_717263_2024-07-24_10-40-05_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_751004_2024-12-20_13-26-07_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_751004_2024-12-21_13-28-24_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_751004_2024-12-22_13-09-11_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_751004_2024-12-23_14-19-57_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_751769_2025-01-16_11-31-52_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_751769_2025-01-17_11-37-35_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_751769_2025-01-18_10-15-21_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_758017_2025-02-04_11-57-33_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_758017_2025-02-05_11-42-30_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_758017_2025-02-06_11-26-09_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_758017_2025-02-07_14-11-05_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_751766_2025-02-11_11-53-32_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_751766_2025-02-13_11-31-21_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_751766_2025-02-14_11-37-11_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_751766_2025-02-15_12-08-11_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_751181_2025-02-25_12-12-30_videoprocessed_2025-10-28_23-21-23/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_751181_2025-02-26_11-51-15_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_751181_2025-02-27_11-24-44_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_754897_2025-03-11_12-07-35_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_754897_2025-03-12_12-23-09_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_754897_2025-03-13_11-20-39_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_754897_2025-03-14_11-28-48_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_754897_2025-03-15_11-32-14_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_758018_2025-03-19_11-16-41_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_758018_2025-03-20_11-53-02_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_758018_2025-03-21_11-00-31_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_752014_2025-03-25_12-09-16_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_752014_2025-03-26_11-18-52_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_752014_2025-03-27_12-03-19_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_752014_2025-03-28_11-04-56_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_761038_2025-04-15_10-24-57_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_761038_2025-04-16_10-39-06_videoprocessed_2025-10-29_21-59-07/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_761038_2025-04-17_11-03-12_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_761038_2025-04-18_12-37-37_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/ecephys_763360_2025-04-15_12-16-20_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/ecephys_763360_2025-04-16_13-29-51_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_782394_2025-04-22_10-53-22_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_782394_2025-04-23_10-51-14_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_782394_2025-04-24_12-07-31_videoprocessed_2025-10-29_21-59-07/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_782394_2025-04-25_11-13-18_videoprocessed_2025-10-29_21-59-07/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_763590_2025-05-01_10-59-16_videoprocessed_2025-10-29_21-59-06/pred_outputs/video_preds/video_predictions.csv\",\n",
      "    \"/root/capsule/data/behavior_763590_2025-05-02_11-07-07_videoprocessed_2025-10-29_21-59-07/pred_outputs/video_preds/video_predictions.csv\",\n",
      "]\n",
      "Saved 45 paths to /root/capsule/scratch/pred_csv_list_halloween.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Base directory\n",
    "data_root = Path(\"/root/capsule/data\")\n",
    "\n",
    "# List of session names you provided (unchanged)\n",
    "session_names = [\n",
    "    \"behavior_716325_2024-05-31_10-31-14\",\n",
    "    \"behavior_717121_2024-06-15_10-00-58\",\n",
    "    \"behavior_717259_2024-06-28_11-17-19\",\n",
    "    \"behavior_717263_2024-07-24_10-40-05\",\n",
    "    \"behavior_751004_2024-12-20_13-26-11\",\n",
    "    \"behavior_751004_2024-12-21_13-28-28\",\n",
    "    \"behavior_751004_2024-12-22_13-09-17\",\n",
    "    \"behavior_751004_2024-12-23_14-20-03\",\n",
    "    \"behavior_751769_2025-01-16_11-32-05\",\n",
    "    \"behavior_751769_2025-01-17_11-37-39\",\n",
    "    \"behavior_751769_2025-01-18_10-15-25\",\n",
    "    \"behavior_758017_2025-02-04_11-57-38\",\n",
    "    \"behavior_758017_2025-02-05_11-42-34\",\n",
    "    \"behavior_758017_2025-02-06_11-26-14\",\n",
    "    \"behavior_758017_2025-02-07_14-11-08\",\n",
    "    \"behavior_751766_2025-02-11_11-53-38\",\n",
    "    \"behavior_751766_2025-02-13_11-31-21\",\n",
    "    \"behavior_751766_2025-02-14_11-37-11\",\n",
    "    \"behavior_751766_2025-02-15_12-08-11\",\n",
    "    \"behavior_751181_2025-02-25_12-12-35\",\n",
    "    \"behavior_751181_2025-02-26_11-51-19\",\n",
    "    \"behavior_751181_2025-02-27_11-24-47\",\n",
    "    \"behavior_754897_2025-03-11_12-07-41\",\n",
    "    \"behavior_754897_2025-03-12_12-23-15\",\n",
    "    \"behavior_754897_2025-03-13_11-20-42\",\n",
    "    \"behavior_754897_2025-03-14_11-28-53\",\n",
    "    \"behavior_754897_2025-03-15_11-32-18\",\n",
    "    \"behavior_758018_2025-03-19_11-16-44\",\n",
    "    \"behavior_758018_2025-03-20_11-53-05\",\n",
    "    \"behavior_758018_2025-03-21_11-00-34\",\n",
    "    \"behavior_752014_2025-03-25_12-09-20\",\n",
    "    \"behavior_752014_2025-03-26_11-18-57\",\n",
    "    \"behavior_752014_2025-03-27_12-03-59\",\n",
    "    \"behavior_752014_2025-03-28_11-04-59\",\n",
    "    \"behavior_761038_2025-04-15_10-25-11\",\n",
    "    \"behavior_761038_2025-04-16_10-39-10\",\n",
    "    \"behavior_761038_2025-04-17_11-03-16\",\n",
    "    \"behavior_761038_2025-04-18_12-37-39\",\n",
    "    \"ecephys_763360_2025-04-15_12-16-29\",\n",
    "    \"ecephys_763360_2025-04-16_13-29-55\",\n",
    "    \"behavior_782394_2025-04-22_10-53-28\",\n",
    "    \"behavior_782394_2025-04-23_10-51-17\",\n",
    "    \"behavior_782394_2025-04-24_12-07-34\",\n",
    "    \"behavior_782394_2025-04-25_11-13-21\",\n",
    "    \"behavior_763590_2025-05-01_10-59-18\",\n",
    "    \"behavior_763590_2025-05-02_11-07-09\",\n",
    "    \"behavior_781166_2025-05-13_14-04-27\",\n",
    "    \"behavior_781166_2025-05-14_14-18-28\",\n",
    "    \"behavior_781166_2025-05-15_14-20-51\",\n",
    "]\n",
    "\n",
    "pred_csv_list = []\n",
    "\n",
    "# --- Code Ocean client ---\n",
    "client = CodeOcean(\n",
    "    domain=\"https://codeocean.allenneuraldynamics.org\",\n",
    "    token=os.getenv(\"API_SECRET\"),\n",
    ")\n",
    "\n",
    "# Helper to parse the videoprocessed timestamp from asset.name\n",
    "_vp_pat = re.compile(r\"_videoprocessed_(\\d{4}-\\d{2}-\\d{2})_(\\d{2}-\\d{2}-\\d{2})$\")\n",
    "_allowed_days = {\"2025-10-28\", \"2025-10-29\"}\n",
    "\n",
    "def _parse_vp_dt(asset_name: str):\n",
    "    m = _vp_pat.search(asset_name)\n",
    "    if not m:\n",
    "        return None, None\n",
    "    day, hms = m.group(1), m.group(2)\n",
    "    try:\n",
    "        return day, datetime.strptime(f\"{day}_{hms}\", \"%Y-%m-%d_%H-%M-%S\")\n",
    "    except Exception:\n",
    "        return day, None\n",
    "\n",
    "for session in session_names:\n",
    "    # Extract base (everything up to YYYY-MM-DD)   [unchanged]\n",
    "    match = re.match(r\"^(.*\\d{4}-\\d{2}-\\d{2})\", session)\n",
    "    if not match:\n",
    "        print(f\"⚠️ Could not parse session name: {session}\")\n",
    "        continue\n",
    "    session_base = match.group(1)\n",
    "\n",
    "    # --- Use CO API to find assets for this session_base ---\n",
    "    try:\n",
    "        params = DataAssetSearchParams(\n",
    "            offset=0, limit=200, sort_order=\"desc\", sort_field=\"name\",\n",
    "            archived=False, favorite=False, query=f\"name:{session_base}\"\n",
    "        )\n",
    "        res = client.data_assets.search_data_assets(params)\n",
    "        # keep only assets that contain '_videoprocessed_' AND were processed on allowed days\n",
    "        vp_assets = []\n",
    "        for a in res.results:\n",
    "            if \"_videoprocessed_\" not in a.name:\n",
    "                continue\n",
    "            day, dt = _parse_vp_dt(a.name)\n",
    "            if day in _allowed_days and dt is not None:\n",
    "                vp_assets.append((a, dt))\n",
    "        if not vp_assets:\n",
    "            print(f\"⚠️ No match found for {session}\")\n",
    "            continue\n",
    "\n",
    "        # pick most recent by parsed timestamp (second date after 'videoprocessed')\n",
    "        latest_asset, _latest_dt = max(vp_assets, key=lambda x: x[1])\n",
    "\n",
    "        # Attach using the asset's own mount name (as requested)\n",
    "        attach = [DataAssetAttachParams(id=latest_asset.id, mount=latest_asset.mount)]\n",
    "        _ = client.capsules.attach_data_assets(\n",
    "            capsule_id=os.getenv(\"CO_CAPSULE_ID\"),\n",
    "            attach_params=attach,\n",
    "        )\n",
    "\n",
    "        # The folder for this session is the mounted path under data_root\n",
    "        folder = data_root / latest_asset.mount\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ CO API error for {session}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # --- look for predictions.csv under folder ---\n",
    "    matches = list((folder / \"pred_outputs\" / \"video_preds\").glob(\"*predictions.csv\"))\n",
    "    if not matches:\n",
    "        print(f\"⚠️ No predictions.csv files found for {session}\")\n",
    "    else:\n",
    "        # If multiple matches, pick the most recent (sorted by name)  [unchanged]\n",
    "        csv_path = sorted(matches)[-1]\n",
    "        if csv_path.exists():\n",
    "            pred_csv_list.append(str(csv_path))\n",
    "        else:\n",
    "            print(f\"⚠️ Predictions CSV missing for {session}\")\n",
    "\n",
    "# Print and save results (unchanged)\n",
    "print(\"pred_csv_list = [\")\n",
    "for path in pred_csv_list:\n",
    "    print(f'    \"{path}\",')\n",
    "print(\"]\")\n",
    "\n",
    "save_path = Path(\"/root/capsule/scratch/pred_csv_list_halloween.json\")\n",
    "save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(pred_csv_list, f, indent=2)\n",
    "\n",
    "print(f\"Saved {len(pred_csv_list)} paths to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5addbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
