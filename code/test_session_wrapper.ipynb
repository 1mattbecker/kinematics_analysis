{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyarrow\n",
    "# pip install opencv-python==4.11.0.86\n",
    "# pip install moviepy==1.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json\n",
    "from aind_dynamic_foraging_behavior_video_analysis.kinematics.tongue_kinematics_utils import get_session_name_from_path, plot_keypoint_confidence_analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aind_dynamic_foraging_behavior_video_analysis.kinematics.tongue_kinematics_utils import get_trial_level_df\n",
    "\n",
    "# def get_trial_level_df(nwb_df_licks, nwb_df_trials):\n",
    "#     # Aggregate licks per trial\n",
    "#     licks_per_trial = nwb_df_licks.groupby('trial').size().rename('lick_count')\n",
    "#     # Aggregate coverage per trial: percent of licks with a movement\n",
    "#     covered = nwb_df_licks['nearest_movement_id'].notna().groupby(nwb_df_licks['trial']).mean().rename('coverage_pct')\n",
    "#     # Lick count in first 10s of each trial\n",
    "#     first_licks = []\n",
    "#     for trial, row in nwb_df_trials.set_index('trial').iterrows():\n",
    "#         start = row['goCue_start_time_in_session']\n",
    "#         end = start + 10\n",
    "#         licks_in_window = nwb_df_licks[\n",
    "#             (nwb_df_licks['trial'] == trial) &\n",
    "#             (nwb_df_licks['timestamps'] >= start) &\n",
    "#             (nwb_df_licks['timestamps'] < end)\n",
    "#         ]\n",
    "#         first_licks.append(len(licks_in_window))\n",
    "#     first10s_lick_count = pd.Series(first_licks, index=nwb_df_trials['trial'], name='first10s_lick_count')\n",
    "#     # Merge with trial info\n",
    "#     trial_df = nwb_df_trials.set_index('trial').join([licks_per_trial, covered, first10s_lick_count])\n",
    "#     trial_df['lick_count'] = trial_df['lick_count'].fillna(0).astype(int)\n",
    "#     trial_df['coverage_pct'] = trial_df['coverage_pct'] * 100\n",
    "#     trial_df['first10s_lick_count'] = trial_df['first10s_lick_count'].fillna(0).astype(int)\n",
    "#     return trial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aind_dynamic_foraging_behavior_video_analysis.kinematics.tongue_analysis import generate_tongue_dfs\n",
    "\n",
    "# def generate_tongue_dfs(predictions_csv_path: Path, data_root: Path, tolerance=0.01):\n",
    "#     \"\"\"\n",
    "#     Runs the full pipeline for one session and returns the NWB object, \n",
    "#     annotated tongue kinematics, and aggregated tongue movements.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     predictions_csv_path : Path\n",
    "#         Path to the predictions CSV (LP_csv).\n",
    "#     data_root : Path\n",
    "#         Root folder containing behavior_<…> session subfolders.\n",
    "#     tolerance : float, optional\n",
    "#         Lick-kinematics matching tolerance (default 0.01).\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     tuple : (nwb, tongue_kin, tongue_movs)\n",
    "#         nwb: NWBFile object with annotated licks/trials added\n",
    "#         tongue_kin: frame-level annotated tongue kinematics (DataFrame)\n",
    "#         tongue_movs: movement-level aggregated tongue movements (DataFrame)\n",
    "#     \"\"\"\n",
    "#     # === Imports inside so function is self-contained ===\n",
    "#     from aind_dynamic_foraging_behavior_video_analysis.kinematics.kinematics_nwb_utils import get_nwb_file\n",
    "#     from aind_dynamic_foraging_behavior_video_analysis.kinematics.tongue_kinematics_utils import (\n",
    "#         load_keypoints_from_csv, find_behavior_videos_folder,\n",
    "#         integrate_keypoints_with_video_time, mask_keypoint_data,\n",
    "#         kinematics_filter, segment_movements_trimnans,\n",
    "#         annotate_trials_in_kinematics, annotate_licks_in_kinematics,\n",
    "#         assign_movements_to_licks, aggregate_tongue_movements,\n",
    "#         add_lick_metadata_to_movements, get_session_name_from_path\n",
    "#     )\n",
    "#     import aind_dynamic_foraging_data_utils.nwb_utils as nwb_utils\n",
    "#     from aind_dynamic_foraging_basic_analysis.licks import annotation\n",
    "\n",
    "#     # === 1) Session detection ===\n",
    "#     lp_csv = predictions_csv_path\n",
    "#     session_id = get_session_name_from_path(str(lp_csv))\n",
    "#     print(f\"\\n=== Generating tongue data for session: {session_id} ===\")\n",
    "#     print(f\"Predictions CSV: {lp_csv}\")\n",
    "\n",
    "#     # === 2) Load keypoints ===\n",
    "#     kps = load_keypoints_from_csv(str(lp_csv))\n",
    "#     print(f\"Loaded keypoints: {len(kps)} raw dataframes\")\n",
    "\n",
    "#     # === 3) Locate synced video CSV ===\n",
    "#     videos_folder = find_behavior_videos_folder(str(data_root / session_id))\n",
    "#     if videos_folder is None:\n",
    "#         raise FileNotFoundError(f\"Videos folder not found for session {session_id}\")\n",
    "#     video_csv = Path(videos_folder) / \"bottom_camera.csv\"\n",
    "#     if not video_csv.exists():\n",
    "#         raise FileNotFoundError(f\"Expected video CSV at {video_csv}\")\n",
    "#     print(f\"Found video CSV: {video_csv}\")\n",
    "\n",
    "#     # === 4) Sync keypoints to video time ===\n",
    "#     kps_trim, _ = integrate_keypoints_with_video_time(str(video_csv), kps)\n",
    "#     print(f\"Synced keypoints\")\n",
    "\n",
    "#     # === 5) Tongue movement segmentation ===\n",
    "#     tongue_masked = mask_keypoint_data(kps_trim, 'tongue_tip_center', confidence_threshold=0.90)\n",
    "#     tongue_filtered = kinematics_filter(tongue_masked, cutoff_freq=50, filter_order=4, filter_kind='cubic')\n",
    "#     tongue_seg = segment_movements_trimnans(tongue_filtered, max_dropped_frames=10)\n",
    "#     print(f\"Segmented {tongue_seg['movement_id'].nunique()} unique movements\")\n",
    "\n",
    "#     # === 6) Load NWB and annotate ===\n",
    "#     nwb = get_nwb_file(session_id)\n",
    "#     nwb.df_events = nwb_utils.create_events_df(nwb)\n",
    "#     nwb.df_trials = nwb_utils.create_df_trials(nwb)\n",
    "#     nwb.df_licks = annotation.annotate_licks(nwb)\n",
    "#     print(f\"NWB load: {len(nwb.df_trials)} trials, {len(nwb.df_licks)} licks\")\n",
    "\n",
    "#     tongue_annot = annotate_trials_in_kinematics(tongue_seg, nwb.df_trials)\n",
    "#     tongue_kin = annotate_licks_in_kinematics(tongue_annot, nwb.df_licks, tolerance=tolerance)\n",
    "#     nwb.df_licks = assign_movements_to_licks(tongue_kin, nwb.df_licks)\n",
    "#     print(\"Annotated kinematics with trials & licks\")\n",
    "\n",
    "#     # === 7) Aggregate movements ===\n",
    "#     tongue_movs = aggregate_tongue_movements(tongue_kin, kps_trim)\n",
    "#     tongue_movs = add_lick_metadata_to_movements(\n",
    "#         tongue_movs, nwb.df_licks, fields=['cue_response','rewarded','event']\n",
    "#     )\n",
    "#     print(f\"Aggregated movements DF shape: {tongue_movs.shape}\")\n",
    "\n",
    "#     # === 8) Trial-level DF ===\n",
    "#     tongue_trials = get_trial_level_df(nwb.df_licks, nwb.df_trials)\n",
    "#     print(f\"Aggregated trial-level DF shape: {tongue_trials.shape}\")\n",
    "\n",
    "#     return nwb, tongue_kin, tongue_movs, kps_trim, tongue_trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aind_dynamic_foraging_behavior_video_analysis.kinematics.tongue_kinematics_utils import select_percentile_movements, plot_movement_tiles_scatter\n",
    "\n",
    "# def select_percentile_movements(\n",
    "#     df: pd.DataFrame,\n",
    "#     metric_col: str,\n",
    "#     percentiles: list = [0, 0.25, 0.5, 0.75, 1.0]\n",
    "# ) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Return movement_ids and corresponding metric values at specified percentiles.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     df : pd.DataFrame\n",
    "#         Must contain 'movement_id' and the metric column.\n",
    "#     metric_col : str\n",
    "#         Name of the numeric column to sort and index into.\n",
    "#     percentiles : list of float\n",
    "#         Values between 0 and 1 for desired percentiles.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     pd.DataFrame\n",
    "#         Columns: ['movement_id', metric_col, 'percentile']\n",
    "#     \"\"\"\n",
    "#     if metric_col not in df.columns:\n",
    "#         raise ValueError(f\"Column '{metric_col}' not found\")\n",
    "#     series = df[['movement_id', metric_col]].dropna()\n",
    "#     if not pd.api.types.is_numeric_dtype(series[metric_col]):\n",
    "#         raise ValueError(f\"Column '{metric_col}' must be numeric\")\n",
    "#     if any(p < 0 or p > 1 for p in percentiles):\n",
    "#         raise ValueError(\"Percentiles must be in [0, 1]\")\n",
    "\n",
    "#     sorted_df = series.sort_values(metric_col).reset_index(drop=True)\n",
    "#     N = len(sorted_df)\n",
    "#     if N == 0:\n",
    "#         return pd.DataFrame(columns=['movement_id', metric_col, 'percentile'])\n",
    "\n",
    "#     rows = []\n",
    "#     for p in percentiles:\n",
    "#         idx = int(round(p * (N - 1)))\n",
    "#         rows.append({\n",
    "#             'movement_id': int(sorted_df.loc[idx, 'movement_id']),\n",
    "#             metric_col: sorted_df.loc[idx, metric_col],\n",
    "#             'percentile': p\n",
    "#         })\n",
    "\n",
    "#     return pd.DataFrame(rows)\n",
    "\n",
    "# def plot_movement_tiles_scatter(\n",
    "#     tongue_segmented: pd.DataFrame,\n",
    "#     movement_ids: list,\n",
    "#     x_col: str,\n",
    "#     y_col: str,\n",
    "#     labels: list = None,\n",
    "#     color: str = 'gray',\n",
    "#     s: int = 5,\n",
    "#     title: str = None,\n",
    "#     return_fig=False\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Plot scatter of any two kinematic columns for a given list of movement_ids.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     tongue_segmented : pd.DataFrame\n",
    "#         Frame-level data with at least 'movement_id', x_col, y_col.\n",
    "#     movement_ids : list\n",
    "#         Movement IDs to plot (one subplot per movement).\n",
    "#     x_col : str\n",
    "#         Column in tongue_segmented to plot on x-axis.\n",
    "#     y_col : str\n",
    "#         Column in tongue_segmented to plot on y-axis.\n",
    "#     labels : list, optional\n",
    "#         List of strings or values to annotate each subplot (same length as movement_ids).\n",
    "#     color : str\n",
    "#         Point color for scatter.\n",
    "#     s : int\n",
    "#         Point size for scatter.\n",
    "#     title : str\n",
    "#         Title of figure\n",
    "#     \"\"\"\n",
    "#     n = len(movement_ids)\n",
    "#     fig, axes = plt.subplots(1, n, figsize=(n * 2, 2), sharex=True, sharey=True)\n",
    "#     if n == 1:\n",
    "#         axes = [axes]\n",
    "\n",
    "#     # Global axis limits\n",
    "#     all_x, all_y = [], []\n",
    "#     for mid in movement_ids:\n",
    "#         df = tongue_segmented[tongue_segmented['movement_id'] == mid]\n",
    "#         df = df[[x_col, y_col]].dropna()\n",
    "#         all_x.extend(df[x_col])\n",
    "#         all_y.extend(df[y_col])\n",
    "#     if not all_x:\n",
    "#         raise RuntimeError(\"No valid movements found to plot.\")\n",
    "#     xlim = (min(all_x), max(all_x))\n",
    "#     ylim = (min(all_y), max(all_y))\n",
    "\n",
    "#     for i, (ax, mid) in enumerate(zip(axes, movement_ids)):\n",
    "#         df = tongue_segmented[tongue_segmented['movement_id'] == mid]\n",
    "#         df = df[[x_col, y_col]].dropna()\n",
    "\n",
    "#         if len(df) < 1:\n",
    "#             ax.scatter([0], [0], s=10, color='black')\n",
    "#         else:\n",
    "#             ax.scatter(df[x_col], df[y_col], s=s, color=color)\n",
    "\n",
    "#         ax.set_xlim(xlim)\n",
    "#         ax.set_ylim(ylim)\n",
    "#         ax.set_xlabel(x_col, fontsize=7)\n",
    "#         if ax == axes[0]:\n",
    "#             ax.set_ylabel(y_col, fontsize=7)\n",
    "\n",
    "#         if labels is not None:\n",
    "#             ax.set_title(str(labels[i]), fontsize=8)\n",
    "    \n",
    "#     if title:\n",
    "#         plt.suptitle(title, fontsize=10)\n",
    "#     else:\n",
    "#         plt.suptitle(f\"{y_col} vs {x_col}\", fontsize=10)\n",
    "    \n",
    "#     # plt.suptitle(f\"{y_col} vs {x_col}\", fontsize=10)\n",
    "#     plt.tight_layout()\n",
    "#     if return_fig:\n",
    "#         return fig\n",
    "#     else:\n",
    "#         plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aind_dynamic_foraging_behavior_video_analysis.kinematics.tongue_analysis import analyze_tongue_movement_quality\n",
    "\n",
    "# def analyze_tongue_movement_quality(\n",
    "#     kps_raw: dict,\n",
    "#     tongue_kins: pd.DataFrame,\n",
    "#     tongue_movs: pd.DataFrame,\n",
    "#     tongue_trials: pd.DataFrame,  # <-- new\n",
    "#     nwb,\n",
    "#     save_dir: str,\n",
    "#     percentiles: list = [0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0],\n",
    "#     pred_csv=None \n",
    "# ):\n",
    "\n",
    "#     \"\"\"\n",
    "#     Analyze and visualize tongue movement quality for a single session.\n",
    "\n",
    "#     Saves figures and key summary stats in a session-specific folder.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     tongue_kins : pd.DataFrame\n",
    "#         Frame-level kinematics data.\n",
    "#     tongue_movs : pd.DataFrame\n",
    "#         Movement-level kinematics data (one row per movement).\n",
    "#     nwb : NWB object with df_licks.\n",
    "#     pred_csv : str\n",
    "#         Path to the prediction CSV (used to infer session name).\n",
    "#     save_dir : str\n",
    "#         Directory where results will be saved.\n",
    "#     percentiles : list\n",
    "#         Percentiles to sample for movement quality plots.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # ----------------\n",
    "#     # Setup & Folders\n",
    "#     # ----------------\n",
    "#     os.makedirs(save_dir, exist_ok=True)\n",
    "#     session_id = os.path.basename(save_dir)\n",
    "\n",
    "#     print(f\"Analyzing session: {session_id}\")\n",
    "    \n",
    "#     # ----------------\n",
    "#     # Confidence figure\n",
    "#     # ----------------\n",
    "#     keypt = 'tongue_tip_center'  # Example, can be parameterized in wrapper\n",
    "#     plot_keypoint_confidence_analysis(\n",
    "#         keypoint_dfs=kps_raw,\n",
    "#         keypt=keypt,\n",
    "#         save_dir=save_dir,\n",
    "#         save_figures=True\n",
    "#         )\n",
    "        \n",
    "#     # ----------------\n",
    "#     # Lick Coverage from trial-level DF\n",
    "#     # ----------------\n",
    "#     total_licks = tongue_trials['lick_count'].sum()\n",
    "#     with_mov = (tongue_trials['coverage_pct'] * tongue_trials['lick_count'] / 100).sum()\n",
    "#     coverage_pct = 100 * with_mov / total_licks if total_licks else np.nan\n",
    "\n",
    "#     lick_movs = tongue_movs[tongue_movs['has_lick']]\n",
    "#     lick_times = nwb.df_licks['timestamps']\n",
    "#     has_mov = nwb.df_licks['nearest_movement_id'].notna()\n",
    "#     covered_times = lick_times[has_mov]\n",
    "#     missed_times = lick_times[~has_mov]\n",
    "\n",
    "#     # ----------------\n",
    "#     # Lick Coverage Figure\n",
    "#     # ----------------\n",
    "#     fig = plt.figure(constrained_layout=True, figsize=(14, 8))\n",
    "#     parent_gs = fig.add_gridspec(2, 1, height_ratios=[1, 1])\n",
    "#     gs_top = parent_gs[0].subgridspec(1, 3, width_ratios=[0.5, 6, 3])\n",
    "#     gs_bottom = parent_gs[1].subgridspec(1, 3)\n",
    "\n",
    "#     ax_cov = fig.add_subplot(gs_top[0, 0])\n",
    "#     ax_raster = fig.add_subplot(gs_top[0, 1])\n",
    "#     ax_scat = fig.add_subplot(gs_top[0, 2])\n",
    "#     ax_h0 = fig.add_subplot(gs_bottom[0, 0])\n",
    "#     ax_h1 = fig.add_subplot(gs_bottom[0, 1])\n",
    "#     ax_h2 = fig.add_subplot(gs_bottom[0, 2])\n",
    "\n",
    "#     # --- Coverage Bar ---\n",
    "#     n_missed = total_licks - with_mov\n",
    "#     ax_cov.bar(0, coverage_pct, color='green', label=f'Covered (n={with_mov})')\n",
    "#     ax_cov.bar(0, 100 - coverage_pct, bottom=coverage_pct,\n",
    "#                color='red', label=f'Missed (n={n_missed})')\n",
    "#     ax_cov.set_ylim(0, 100)\n",
    "#     ax_cov.set_xticks([])\n",
    "#     ax_cov.set_title(\"Lick Coverage (%)\", fontsize=10)\n",
    "#     ax_cov.legend(fontsize=7, loc='lower center')\n",
    "\n",
    "#     # --- Raster ---\n",
    "#     ax_raster.eventplot(\n",
    "#         [covered_times, missed_times],\n",
    "#         lineoffsets=[1, 0], linelengths=0.8,\n",
    "#         colors=['green', 'red']\n",
    "#     )\n",
    "#     ax_raster.set_yticks([1, 0])\n",
    "#     ax_raster.set_yticklabels(['Covered', 'Missed'])\n",
    "#     ax_raster.set_xlabel('Time in session (s)')\n",
    "#     ax_raster.set_title('Lick coverage over session')\n",
    "\n",
    "#     # --- Scatter ---\n",
    "#     ax_scat.scatter(lick_movs['duration'], lick_movs['dropped_frames_pct'],\n",
    "#                     alpha=0.05, edgecolor='k')\n",
    "#     ax_scat.set_xlabel('Duration (s)')\n",
    "#     ax_scat.set_ylabel('Dropped Frame %')\n",
    "#     ax_scat.set_title('Duration vs Drop%')\n",
    "\n",
    "#     # --- Histograms ---\n",
    "#     ax_h0.hist(lick_movs['n_datapoints'], bins=30)\n",
    "#     ax_h0.set(title='Datapoints')\n",
    "#     ax_h1.hist(lick_movs['duration'], bins=30)\n",
    "#     ax_h1.set(title='Duration')\n",
    "#     ax_h2.hist(lick_movs['dropped_frames_pct'], bins=30)\n",
    "#     ax_h2.set(title='Dropped %')\n",
    "\n",
    "#     plt.suptitle(f'{session_id}', y=1.02)\n",
    "#     fig.savefig(os.path.join(save_dir, \"lick_coverage_summary.png\"), dpi=150)\n",
    "#     plt.close(fig)\n",
    "\n",
    "#     # ----------------\n",
    "#     # Movement Percentile Plots\n",
    "#     # ----------------\n",
    "#     tongue_kins['time_in_movement'] = (\n",
    "#         tongue_kins['time'] -\n",
    "#         tongue_kins.groupby('movement_id')['time'].transform('first')\n",
    "#     )\n",
    "\n",
    "#     percentile_results = {}\n",
    "#     for metric_col in ['dropped_frames_n', 'duration']:\n",
    "#         sel = select_percentile_movements(tongue_movs, metric_col=metric_col, percentiles=percentiles)\n",
    "#         labels = [f\"{int(p*100)}%ile: {val:.2f}\" \n",
    "#                   for p, val in zip(sel['percentile'], sel[metric_col])]\n",
    "#         percentile_results[metric_col] = dict(zip(sel['percentile'], sel[metric_col]))\n",
    "\n",
    "\n",
    "#         fig = plot_movement_tiles_scatter(\n",
    "#             tongue_segmented=tongue_kins,\n",
    "#             movement_ids=sel['movement_id'].tolist(),\n",
    "#             x_col='time_in_movement',\n",
    "#             y_col='x',\n",
    "#             labels=labels,\n",
    "#             color='gray',\n",
    "#             title=metric_col,\n",
    "#             return_fig=True\n",
    "#         )\n",
    "#         fig.savefig(os.path.join(save_dir, f\"{metric_col}_tiles.png\"), dpi=150)\n",
    "#         plt.close(fig)\n",
    "\n",
    "#     # ----------------\n",
    "#     # Save Everything to JSON\n",
    "#     # ----------------\n",
    "#     results_dict = {\n",
    "#         \"session_id\": os.path.basename(save_dir),\n",
    "#         \"pred_csv\": str(pred_csv) if pred_csv else None,\n",
    "#         \"total_licks\": int(total_licks),\n",
    "#         \"licks_with_movement\": int(with_mov),\n",
    "#         \"coverage_pct\": float(coverage_pct),\n",
    "#         \"percentiles\": percentile_results\n",
    "#     }\n",
    "\n",
    "#     with open(os.path.join(save_dir, \"tongue_quality_stats.json\"), \"w\") as f:\n",
    "#         json.dump(results_dict, f, indent=2)\n",
    "\n",
    "#     print(f\"✅ Finished analysis for {session_id}. Results saved to {save_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aind_dynamic_foraging_behavior_video_analysis.kinematics.tongue_analysis import run_batch_analysis\n",
    "\n",
    "# def run_batch_analysis(\n",
    "#     pred_csv_list, \n",
    "#     data_root, \n",
    "#     save_root, \n",
    "#     percentiles=None, \n",
    "#     extract_clips=True  \n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Run analysis for multiple sessions in batch.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     pred_csv_list : list of str or Path\n",
    "#         List of prediction CSV paths (one per session).\n",
    "#     data_root : str or Path\n",
    "#         Root folder where behavior_<...> session folders live.\n",
    "#     save_root : str or Path\n",
    "#         Root folder to save all analysis outputs.\n",
    "#     percentiles : list, optional\n",
    "#         Percentiles for movement quality plots (default: [0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0]).\n",
    "#     extract_clips : bool, optional\n",
    "#         Whether to extract example video clips for each session (default: True).\n",
    "#     \"\"\"\n",
    "#     percentiles = percentiles or [0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0]\n",
    "#     save_root = Path(save_root)\n",
    "#     save_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     error_log = []\n",
    "\n",
    "#     for pred_csv in pred_csv_list:\n",
    "#         pred_csv = Path(pred_csv)\n",
    "#         session_id = get_session_name_from_path(str(pred_csv))\n",
    "\n",
    "#         print(f\"\\n🔹 Starting analysis for: {session_id}\")\n",
    "#         session_save_dir = os.path.join(save_root, session_id)\n",
    "#         os.makedirs(session_save_dir, exist_ok=True)\n",
    "\n",
    "#         try:\n",
    "#             # ---- 1) Generate DFs ----\n",
    "#             nwb, tongue_kins, tongue_movs, kps_raw, tongue_trials = generate_tongue_dfs(pred_csv, data_root)\n",
    "\n",
    "#             # ---- 1a) Save intermediate data ----\n",
    "#             intermediate_folder = os.path.join(session_save_dir, \"intermediate_data\")\n",
    "#             os.makedirs(intermediate_folder, exist_ok=True)\n",
    "\n",
    "#             # Save tongue_kins and tongue_movs\n",
    "#             tongue_kins.to_parquet(os.path.join(intermediate_folder, \"tongue_kins.parquet\"))\n",
    "#             tongue_movs.to_parquet(os.path.join(intermediate_folder, \"tongue_movs.parquet\"))\n",
    "#             tongue_trials.to_parquet(os.path.join(intermediate_folder, \"tongue_trials.parquet\"))\n",
    "\n",
    "#             # Save each df in kps_raw dict\n",
    "#             for key, df in kps_raw.items():\n",
    "#                 df.to_parquet(os.path.join(intermediate_folder, f\"kps_raw_{key}.parquet\"))\n",
    "\n",
    "#             # Save selected NWB dfs\n",
    "#             nwb.df_licks.to_parquet(os.path.join(intermediate_folder, \"nwb_df_licks.parquet\"))\n",
    "#             nwb.df_trials.to_parquet(os.path.join(intermediate_folder, \"nwb_df_trials.parquet\"))\n",
    "#             nwb.df_events.to_parquet(os.path.join(intermediate_folder, \"nwb_df_events.parquet\"))\n",
    "\n",
    "#             # ---- 2) Run analysis ----\n",
    "#             analyze_tongue_movement_quality(\n",
    "#                 kps_raw=kps_raw,\n",
    "#                 tongue_kins=tongue_kins,\n",
    "#                 tongue_movs=tongue_movs,\n",
    "#                 tongue_trials=tongue_trials,\n",
    "#                 nwb=nwb,\n",
    "#                 save_dir=session_save_dir,\n",
    "#                 percentiles=percentiles,\n",
    "#                 pred_csv=pred_csv\n",
    "#             )\n",
    "\n",
    "#             # ---- 3) Optionally extract example clips ----\n",
    "#             if extract_clips:\n",
    "#                 try:\n",
    "#                     extract_example_clips_for_session(\n",
    "#                         session_id, \n",
    "#                         save_root,  # analysis_root\n",
    "#                         data_root\n",
    "#                     )\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Warning: Could not extract clips for {session_id}: {e}\")\n",
    "\n",
    "#         except Exception as e:\n",
    "#             error_msg = f\"❌ Error in {session_id}: {repr(e)}\"\n",
    "#             print(error_msg)\n",
    "#             error_log.append(error_msg)\n",
    "#             continue  # Move to the next session\n",
    "\n",
    "#     # ---- Print & Save Error Log ----\n",
    "#     if error_log:\n",
    "#         log_file = save_root / \"batch_error_log.txt\"\n",
    "#         with open(log_file, \"w\") as f:\n",
    "#             f.write(\"\\n\".join(error_log))\n",
    "#         print(f\"\\n⚠️ Completed with errors. See log: {log_file}\")\n",
    "#     else:\n",
    "#         print(\"\\n✅ Batch analysis completed successfully for all sessions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from aind_dynamic_foraging_behavior_video_analysis.kinematics.video_clip_utils import extract_clips_ffmpeg_after_reencode\n",
    "\n",
    "def find_labeled_video(session_id, data_root):\n",
    "    # Find the labeled video file for a session_id, searching for any folder that starts with session_id\n",
    "    data_root = Path(data_root)\n",
    "    for subdir in data_root.glob(f\"{session_id}*\"):\n",
    "        candidate = subdir / \"pred_outputs\" / \"video_preds\" / \"labeled_videos\" / \"bottom_camera_labeled.mp4\"\n",
    "        if candidate.exists():\n",
    "            return str(candidate)\n",
    "    raise FileNotFoundError(f\"Labeled video not found for {session_id}\")\n",
    "\n",
    "def get_video_time(session_time, tongue_kins):\n",
    "    # Find offset between session time and video time using first row\n",
    "    offset = tongue_kins.iloc[0]['time'] - tongue_kins.iloc[0]['time_in_session']\n",
    "    return session_time + offset\n",
    "\n",
    "def extract_trial_clip(\n",
    "    session_id, trial_row, tongue_kins, video_path, save_dir,\n",
    "    clip_duration_s=10.0, pad_s=0.5\n",
    "):\n",
    "    start = trial_row['goCue_start_time_in_session']\n",
    "    end = start + clip_duration_s\n",
    "\n",
    "    # Convert to video time\n",
    "    video_start = get_video_time(start, tongue_kins) - pad_s\n",
    "    video_end = get_video_time(end, tongue_kins) + pad_s\n",
    "    clip_length = video_end - video_start\n",
    "\n",
    "    # Filename\n",
    "    trial_num = trial_row.name if hasattr(trial_row, 'name') else trial_row['trial']\n",
    "    filename_stem = f\"trial_{trial_num}\"\n",
    "\n",
    "    extract_clips_ffmpeg_after_reencode(\n",
    "        video_path, [video_start], clip_length, save_dir, filename_stems=[filename_stem]\n",
    "    )\n",
    "    print(f\"Saved clip for trial {trial_num} to {save_dir}\")\n",
    "\n",
    "    \n",
    "def extract_example_clips_for_session(session_id, analysis_root, data_root):\n",
    "    # Load data\n",
    "    inter_dir = Path(analysis_root) / session_id / \"intermediate_data\"\n",
    "    tongue_movs = pd.read_parquet(inter_dir / \"tongue_movs.parquet\")\n",
    "    tongue_kins = pd.read_parquet(inter_dir / \"tongue_kins.parquet\")\n",
    "    nwb_df_licks = pd.read_parquet(inter_dir / \"nwb_df_licks.parquet\")\n",
    "    nwb_df_trials = pd.read_parquet(inter_dir / \"nwb_df_trials.parquet\")\n",
    "    # Get trial-level stats\n",
    "    trial_df = get_trial_level_df(nwb_df_licks, nwb_df_trials)\n",
    "    \n",
    "    # Only consider trials with at least 5 licks\n",
    "    trial_df = trial_df[trial_df['first10s_lick_count'] >= 5]\n",
    "\n",
    "    # # Find trial with highest and lowest coverage (among those with high lick count)\n",
    "    # Top 3 trials by coverage\n",
    "    top3 = trial_df.sort_values(['coverage_pct', 'lick_count'], ascending=[False, False]).head(3)\n",
    "    # Bottom 3 trials by coverage\n",
    "    bottom3 = trial_df.sort_values(['coverage_pct', 'lick_count'], ascending=[True, False]).head(3)\n",
    "\n",
    "    # Output dirs\n",
    "    good_dir = Path(analysis_root) / session_id / \"example_clips\" / \"good\"\n",
    "    bad_dir = Path(analysis_root) / session_id / \"example_clips\" / \"bad\"\n",
    "    good_dir.mkdir(exist_ok=True, parents=True)\n",
    "    bad_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # Try to find video, but allow plotting if not found\n",
    "    try:\n",
    "        video_path = find_labeled_video(session_id, data_root)\n",
    "        video_found = True\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: No labeled video found for {session_id}. Skipping video extraction, will plot only.\")\n",
    "        video_found = False\n",
    "\n",
    "    for _, trial_row in top3.iterrows():\n",
    "        if video_found:\n",
    "            extract_trial_clip(session_id, trial_row, tongue_kins, video_path, good_dir,\n",
    "                               clip_duration_s=10, pad_s=0.5)\n",
    "        fig_path = good_dir / f\"Trial{trial_row.name}_xy_vs_time.png\"\n",
    "        plot_kinematic_vs_time(tongue_kins, trial_row, time_col=\"time_in_session\", value_cols=['x', 'y'],\n",
    "                               save_path=fig_path, licks_df=nwb_df_licks, covered_col=\"nearest_movement_id\", pad_s=0.5)\n",
    "\n",
    "    for _, trial_row in bottom3.iterrows():\n",
    "        if video_found:\n",
    "            extract_trial_clip(session_id, trial_row, tongue_kins, video_path, bad_dir,\n",
    "                               clip_duration_s=10, pad_s=0.5)\n",
    "        fig_path = bad_dir / f\"Trial{trial_row.name}_xy_vs_time.png\"\n",
    "        plot_kinematic_vs_time(tongue_kins, trial_row, time_col=\"time_in_session\", value_cols=['x', 'y'],\n",
    "                               save_path=fig_path, licks_df=nwb_df_licks, covered_col=\"nearest_movement_id\", pad_s=0.5)\n",
    "\n",
    "\n",
    "def plot_kinematic_vs_time(\n",
    "    tongue_kins, trial_row, time_col, value_cols, save_path,\n",
    "    clip_duration_s=None, pad_s=0.5, axes=None, title_prefix=\"\",\n",
    "    licks_df=None,\n",
    "    covered_col='nearest_movement_id'\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots one or more kinematic parameters vs. time in stacked subplots.\n",
    "    Optionally overlays vertical lines for lick times (green=covered, red=missed).\n",
    "\n",
    "    Parameters:\n",
    "        tongue_kins (pd.DataFrame): Kinematics dataframe.\n",
    "        trial_row (pd.Series): Row from trials dataframe.\n",
    "        time_col (str): Name of the time column (e.g., 'session_time').\n",
    "        value_cols (list of str): List of kinematic columns to plot.\n",
    "        save_path (str or Path): Where to save the figure.\n",
    "        clip_duration_s (float or None): If set, use start+clip_duration_s for end, else use bonsai_stop_time_in_session.\n",
    "        pad_s (float): Padding before/after clip window.\n",
    "        axes (list of plt.Axes): Optional list of externally created axes.\n",
    "        title_prefix (str): Optional string prefix for title.\n",
    "        licks_df (pd.DataFrame): DataFrame of licks (must have 'timestamps', 'trial', and coverage col).\n",
    "        covered_col (str): Column in licks_df indicating coverage (notna means covered).\n",
    "    \"\"\"\n",
    "    start = trial_row['goCue_start_time_in_session']\n",
    "    if clip_duration_s is not None:\n",
    "        end = start + clip_duration_s\n",
    "    else:\n",
    "        end = trial_row['bonsai_stop_time_in_session']\n",
    "\n",
    "    window_start = start - pad_s\n",
    "    window_end = end + pad_s\n",
    "\n",
    "    df = tongue_kins[\n",
    "        (tongue_kins[time_col] >= window_start) &\n",
    "        (tongue_kins[time_col] <= window_end)\n",
    "    ]\n",
    "\n",
    "    if axes is None:\n",
    "        fig, axes = plt.subplots(len(value_cols), 1, figsize=(8, 3 * len(value_cols)), sharex=True)\n",
    "        if len(value_cols) == 1:\n",
    "            axes = [axes]  # make iterable if only one plot\n",
    "    else:\n",
    "        fig = axes[0].figure\n",
    "\n",
    "    # For legend handles\n",
    "    covered_handle = None\n",
    "    missed_handle = None\n",
    "\n",
    "    for ax, val_col in zip(axes, value_cols):\n",
    "        ax.scatter(df[time_col], df[val_col], s=5, alpha=0.5, color='gray')\n",
    "        ax.set_ylabel(val_col)\n",
    "        ax.set_xlim(window_start, window_end)\n",
    "\n",
    "    # --- Add vertical lines for licks ---\n",
    "    if licks_df is not None:\n",
    "        trial_num = trial_row.name if 'name' in dir(trial_row) else trial_row['trial']\n",
    "        licks_in_trial = licks_df[licks_df['trial'] == trial_num]\n",
    "        # Filter to window\n",
    "        licks_in_window = licks_in_trial[\n",
    "            (licks_in_trial['timestamps'] >= window_start) &\n",
    "            (licks_in_trial['timestamps'] <= window_end)\n",
    "        ]\n",
    "        # Covered: where covered_col is notna\n",
    "        covered = licks_in_window[licks_in_window[covered_col].notna()]\n",
    "        missed = licks_in_window[licks_in_window[covered_col].isna()]\n",
    "        for t in covered['timestamps']:\n",
    "            for ax in axes:\n",
    "                covered_handle = ax.axvline(\n",
    "                    t, color='green', linestyle='--', alpha=0.7, linewidth=1, label='Covered lick'\n",
    "                )\n",
    "        for t in missed['timestamps']:\n",
    "            for ax in axes:\n",
    "                missed_handle = ax.axvline(\n",
    "                    t, color='red', linestyle='--', alpha=0.7, linewidth=1, label='Missed lick'\n",
    "                )\n",
    "        # Add legend to the top axis only, avoiding duplicate labels\n",
    "        handles = []\n",
    "        labels = []\n",
    "        if covered_handle is not None:\n",
    "            handles.append(covered_handle)\n",
    "            labels.append('Covered lick')\n",
    "        if missed_handle is not None:\n",
    "            handles.append(missed_handle)\n",
    "            labels.append('Missed lick')\n",
    "        if handles:\n",
    "            axes[0].legend(handles, labels, loc='upper left', fontsize=9)\n",
    "\n",
    "    axes[-1].set_xlabel(f\"{time_col} (s)\")\n",
    "    axes[0].set_title(f\"{title_prefix} Trial {trial_row.name}: {', '.join(value_cols)} vs {time_col}\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(save_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Example usage:\n",
    "# extract_example_clips_for_session(\"behavior_751004_2024-12-23_14-19-57\", \"/root/capsule/scratch/session_analysis\", \"/root/capsule/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Starting analysis for: behavior_716325_2024-05-31_10-31-14\n",
      "\n",
      "=== Generating tongue data for session: behavior_716325_2024-05-31_10-31-14 ===\n",
      "Predictions CSV: /root/capsule/data/BottomViewPylon1-MIB-2025-02-17/inference/behavior_716325_2024-05-31_10-31-14/bottom_camera.csv\n",
      "keypoints extracted: ['nose_tip', 'jaw', 'tongue_tip_right', 'tongue_tip_center', 'tongue_tip_left', 'pointer_finger_r', 'paw_wrist_r', 'pointer_finger_l', 'paw_wrist_l', 'spout_r', 'spout_l']\n",
      "Loaded keypoints: 11 raw dataframes\n",
      "Found video CSV: /root/capsule/data/behavior_716325_2024-05-31_10-31-14/behavior-videos/bottom_camera.csv\n",
      "Video QC: Frame numbers are sequential with no gaps.\n",
      "Video QC: Timing differences are within expected range.\n",
      "keypoint_df trimmed from 2689719 to 2689718\n",
      "Synced keypoints\n",
      "Segmented 7258 unique movements\n",
      "Loading NWB from /root/capsule/data/foraging_nwb_bonsai/716325_2024-05-31_10-31-14.nwb\n",
      "Timestamps are adjusted such that `_in_session` timestamps start at the first go cue\n",
      "Timestamps are adjusted such that `_in_session` timestamps start at the first go cue\n",
      "NWB load: 586 trials, 5846 licks\n",
      "Annotated kinematics with trials & licks\n"
     ]
    }
   ],
   "source": [
    "# Batch Analysis \n",
    "\n",
    "save_root = \"/root/capsule/scratch/session_analysis_in_distribution\"\n",
    "data_root = Path(\"/root/capsule/data\")\n",
    "\n",
    "pred_csv_list = [\n",
    "    \"/root/capsule/data/BottomViewPylon1-MIB-2025-02-17/inference/behavior_716325_2024-05-31_10-31-14/bottom_camera.csv\",\n",
    "    \"/root/capsule/data/BottomViewPylon1-MIB-2025-02-17/inference/behavior_717121_2024-06-15_10-00-58/bottom_camera.csv\",\n",
    "    \"/root/capsule/data/BottomViewPylon1-MIB-2025-02-17/inference/behavior_717259_2024-06-28_11-17-19/bottom_camera.csv\",\n",
    "    \"/root/capsule/data/BottomViewPylon1-MIB-2025-02-17/inference/behavior_717263_2024-07-24_10-40-05/bottom_camera.csv\",\n",
    "    \"/root/capsule/data/BottomViewPylon1-MIB-2025-02-17/inference/behavior_751004_2024-12-20_13-26-07/bottom_camera.csv\",\n",
    "    \"/root/capsule/data/BottomViewPylon1-MIB-2025-02-17/inference/behavior_751004_2024-12-21_13-28-24/bottom_camera.csv\",\n",
    "    \"/root/capsule/data/BottomViewPylon1-MIB-2025-02-17/inference/behavior_751004_2024-12-22_13-09-11/bottom_camera.csv\",\n",
    "    \"/root/capsule/data/BottomViewPylon1-MIB-2025-02-17/inference/behavior_751004_2024-12-23_14-19-57/bottom_camera.csv\"\n",
    "]\n",
    "\n",
    "run_batch_analysis(pred_csv_list, data_root, save_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_root = \"/root/capsule/scratch/session_analysis_out_of_distribution\"\n",
    "# data_root = Path(\"/root/capsule/data\")\n",
    "\n",
    "# pred_csv_list = [\n",
    "#     \"/root/capsule/data/behavior_751766_2025-02-11_11-53-32_videoprocessed_2025-07-17/pred_outputs/video_preds/bottom_camera_predictions.csv\",\n",
    "#     \"/root/capsule/data/behavior_754897_2025-03-11_12-07-35_videoprocessed_2025-07-08/pred_outputs/video_preds/bottom_camera_predictions.csv\",\n",
    "#     \"/root/capsule/data/behavior_754897_2025-03-13_11-20-39_videoprocessed_2025-07-17/pred_outputs/video_preds/bottom_camera_predictions.csv\",\n",
    "#     \"/root/capsule/data/behavior_758017_2025-02-04_11-57-33_videoprocessed_2025-07-17/pred_outputs/video_preds/bottom_camera_predictions.csv\",\n",
    "#     \"/root/capsule/data/behavior_761038_2025-04-15_10-24-57_videoprocessed_2025-07-17/pred_outputs/video_preds/bottom_camera_predictions.csv\",\n",
    "#     \"/root/capsule/data/behavior_782394_2025-04-24_12-07-31_videoprocessed_2025-07-17/pred_outputs/video_preds/bottom_camera_predictions.csv\"\n",
    "# ]\n",
    "\n",
    "# run_batch_analysis(pred_csv_list, data_root, save_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Starting analysis for: behavior_716325_2024-05-31_10-31-14\n",
      "\n",
      "=== Generating tongue data for session: behavior_716325_2024-05-31_10-31-14 ===\n",
      "Predictions CSV: /root/capsule/data/BottomViewPylon1-MIB-2025-02-17/inference/behavior_716325_2024-05-31_10-31-14/bottom_camera.csv\n",
      "keypoints extracted: ['nose_tip', 'jaw', 'tongue_tip_right', 'tongue_tip_center', 'tongue_tip_left', 'pointer_finger_r', 'paw_wrist_r', 'pointer_finger_l', 'paw_wrist_l', 'spout_r', 'spout_l']\n",
      "Loaded keypoints: 11 raw dataframes\n",
      "Found video CSV: /root/capsule/data/behavior_716325_2024-05-31_10-31-14/behavior-videos/bottom_camera.csv\n",
      "Video QC: Frame numbers are sequential with no gaps.\n",
      "Video QC: Timing differences are within expected range.\n",
      "keypoint_df trimmed from 2689719 to 2689718\n",
      "Synced keypoints\n",
      "Segmented 7258 unique movements\n",
      "Loading NWB from /root/capsule/data/foraging_nwb_bonsai/716325_2024-05-31_10-31-14.nwb\n",
      "Timestamps are adjusted such that `_in_session` timestamps start at the first go cue\n",
      "Timestamps are adjusted such that `_in_session` timestamps start at the first go cue\n",
      "NWB load: 586 trials, 5846 licks\n"
     ]
    }
   ],
   "source": [
    "#test single session on batch analysis\n",
    "\n",
    "save_root = \"/root/capsule/scratch/refactor_test\" #update save location as needed\n",
    "data_root = Path(\"/root/capsule/data\")\n",
    "\n",
    "pred_csv_list = [\n",
    "        \"/root/capsule/data/BottomViewPylon1-MIB-2025-02-17/inference/behavior_716325_2024-05-31_10-31-14/bottom_camera.csv\"\n",
    "]\n",
    "\n",
    "run_batch_analysis(pred_csv_list, data_root, save_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # look into individual session for errors when generating dfs\n",
    "\n",
    "\n",
    "# data_root = Path(\"/root/capsule/data\")\n",
    "\n",
    "# pred_csv = \"/root/capsule/data/behavior_751766_2025-02-11_11-53-32_videoprocessed_2025-07-17/pred_outputs/video_preds/bottom_camera_predictions.csv\"\n",
    "# session_id = get_session_name_from_path(str(pred_csv))\n",
    "\n",
    "# # ---- 1) Generate DFs ----\n",
    "# nwb, tongue_kins, tongue_movs, kps_raw, tongue_trials = generate_tongue_dfs(pred_csv, data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing plotting function\n",
    "\n",
    "# # Select a trial (first row as example)\n",
    "# trial_row = nwb.df_trials.iloc[25]\n",
    "\n",
    "# # Set output path for the plot\n",
    "# save_path = \"example_trial_kinematics.png\"\n",
    "\n",
    "# # Call the plotting function\n",
    "# plot_kinematic_vs_time(\n",
    "#     tongue_kins=tongue_kins,\n",
    "#     trial_row=trial_row,\n",
    "#     time_col=\"time_in_session\",         # or \"session_time\" if that's your column\n",
    "#     value_cols=[\"x\", \"y\"],              # or any kinematic columns you want to plot\n",
    "#     save_path=save_path,\n",
    "#     licks_df=nwb.df_licks,              # pass the licks DataFrame\n",
    "#     covered_col=\"nearest_movement_id\"   # column indicating coverage\n",
    "# )\n",
    "\n",
    "# print(f\"Plot saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #adding videos later\n",
    "\n",
    "# analysis_root = \"/root/capsule/scratch/session_analysis_in_distribution\"\n",
    "# data_root = \"/root/capsule/data\"\n",
    "\n",
    "# for session_id in os.listdir(analysis_root):\n",
    "#     session_path = os.path.join(analysis_root, session_id)\n",
    "#     inter_dir = os.path.join(session_path, \"intermediate_data\")\n",
    "#     # Check if intermediate data exists and has required files\n",
    "#     required_files = [\n",
    "#         \"tongue_movs.parquet\",\n",
    "#         \"tongue_kins.parquet\",\n",
    "#         \"nwb_df_licks.parquet\",\n",
    "#         \"nwb_df_trials.parquet\"\n",
    "#     ]\n",
    "#     if not os.path.isdir(inter_dir) or not all(os.path.isfile(os.path.join(inter_dir, f)) for f in required_files):\n",
    "#         print(f\"Skipping {session_id}: missing intermediate data.\")\n",
    "#         continue\n",
    "#     try:\n",
    "#         extract_example_clips_for_session(session_id, analysis_root, data_root)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {session_id}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
