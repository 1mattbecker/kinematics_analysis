{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json\n",
    "from aind_dynamic_foraging_behavior_video_analysis.kinematics.tongue_kinematics_utils import get_session_name_from_path, plot_keypoint_confidence_analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_tongue_dfs(predictions_csv_path: Path, data_root: Path, tolerance=0.01):\n",
    "    \"\"\"\n",
    "    Runs the full pipeline for one session and returns the NWB object, \n",
    "    annotated tongue kinematics, and aggregated tongue movements.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions_csv_path : Path\n",
    "        Path to the predictions CSV (LP_csv).\n",
    "    data_root : Path\n",
    "        Root folder containing behavior_<â€¦> session subfolders.\n",
    "    tolerance : float, optional\n",
    "        Lick-kinematics matching tolerance (default 0.01).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple : (nwb, tongue_kin, tongue_movs)\n",
    "        nwb: NWBFile object with annotated licks/trials added\n",
    "        tongue_kin: frame-level annotated tongue kinematics (DataFrame)\n",
    "        tongue_movs: movement-level aggregated tongue movements (DataFrame)\n",
    "    \"\"\"\n",
    "    # === Imports inside so function is self-contained ===\n",
    "    from aind_dynamic_foraging_behavior_video_analysis.kinematics.kinematics_nwb_utils import get_nwb_file\n",
    "    from aind_dynamic_foraging_behavior_video_analysis.kinematics.tongue_kinematics_utils import (\n",
    "        load_keypoints_from_csv, find_behavior_videos_folder,\n",
    "        integrate_keypoints_with_video_time, mask_keypoint_data,\n",
    "        kinematics_filter, segment_movements_trimnans,\n",
    "        annotate_trials_in_kinematics, annotate_licks_in_kinematics,\n",
    "        assign_movements_to_licks, aggregate_tongue_movements,\n",
    "        add_lick_metadata_to_movements, get_session_name_from_path\n",
    "    )\n",
    "    import aind_dynamic_foraging_data_utils.nwb_utils as nwb_utils\n",
    "    from aind_dynamic_foraging_basic_analysis.licks import annotation\n",
    "\n",
    "    # === 1) Session detection ===\n",
    "    lp_csv = predictions_csv_path\n",
    "    session_id = get_session_name_from_path(str(lp_csv))\n",
    "    print(f\"\\n=== Generating tongue data for session: {session_id} ===\")\n",
    "    print(f\"Predictions CSV: {lp_csv}\")\n",
    "\n",
    "    # === 2) Load keypoints ===\n",
    "    kps = load_keypoints_from_csv(str(lp_csv))\n",
    "    print(f\"Loaded keypoints: {len(kps)} raw dataframes\")\n",
    "\n",
    "    # === 3) Locate synced video CSV ===\n",
    "    videos_folder = find_behavior_videos_folder(str(data_root / session_id))\n",
    "    if videos_folder is None:\n",
    "        raise FileNotFoundError(f\"Videos folder not found for session {session_id}\")\n",
    "    video_csv = Path(videos_folder) / \"bottom_camera.csv\"\n",
    "    if not video_csv.exists():\n",
    "        raise FileNotFoundError(f\"Expected video CSV at {video_csv}\")\n",
    "    print(f\"Found video CSV: {video_csv}\")\n",
    "\n",
    "    # === 4) Sync keypoints to video time ===\n",
    "    kps_trim, _ = integrate_keypoints_with_video_time(str(video_csv), kps)\n",
    "    print(f\"Synced keypoints\")\n",
    "\n",
    "    # === 5) Tongue movement segmentation ===\n",
    "    tongue_masked = mask_keypoint_data(kps_trim, 'tongue_tip_center', confidence_threshold=0.90)\n",
    "    tongue_filtered = kinematics_filter(tongue_masked, cutoff_freq=50, filter_order=4, filter_kind='cubic')\n",
    "    tongue_seg = segment_movements_trimnans(tongue_filtered, max_dropped_frames=10)\n",
    "    print(f\"Segmented {tongue_seg['movement_id'].nunique()} unique movements\")\n",
    "\n",
    "    # === 6) Load NWB and annotate ===\n",
    "    nwb = get_nwb_file(session_id)\n",
    "    nwb.df_events = nwb_utils.create_events_df(nwb)\n",
    "    nwb.df_trials = nwb_utils.create_df_trials(nwb)\n",
    "    nwb.df_licks = annotation.annotate_licks(nwb)\n",
    "    print(f\"NWB load: {len(nwb.df_trials)} trials, {len(nwb.df_licks)} licks\")\n",
    "\n",
    "    tongue_annot = annotate_trials_in_kinematics(tongue_seg, nwb.df_trials)\n",
    "    tongue_kin = annotate_licks_in_kinematics(tongue_annot, nwb.df_licks, tolerance=tolerance)\n",
    "    nwb.df_licks = assign_movements_to_licks(tongue_kin, nwb.df_licks)\n",
    "    print(\"Annotated kinematics with trials & licks\")\n",
    "\n",
    "    # === 7) Aggregate movements ===\n",
    "    tongue_movs = aggregate_tongue_movements(tongue_kin, kps_trim)\n",
    "    tongue_movs = add_lick_metadata_to_movements(\n",
    "        tongue_movs, nwb.df_licks, fields=['cue_response','rewarded','event']\n",
    "    )\n",
    "    print(f\"Aggregated movements DF shape: {tongue_movs.shape}\")\n",
    "\n",
    "    return nwb, tongue_kin, tongue_movs, kps_trim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_percentile_movements(\n",
    "    df: pd.DataFrame,\n",
    "    metric_col: str,\n",
    "    percentiles: list = [0, 0.25, 0.5, 0.75, 1.0]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return movement_ids and corresponding metric values at specified percentiles.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain 'movement_id' and the metric column.\n",
    "    metric_col : str\n",
    "        Name of the numeric column to sort and index into.\n",
    "    percentiles : list of float\n",
    "        Values between 0 and 1 for desired percentiles.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Columns: ['movement_id', metric_col, 'percentile']\n",
    "    \"\"\"\n",
    "    if metric_col not in df.columns:\n",
    "        raise ValueError(f\"Column '{metric_col}' not found\")\n",
    "    series = df[['movement_id', metric_col]].dropna()\n",
    "    if not pd.api.types.is_numeric_dtype(series[metric_col]):\n",
    "        raise ValueError(f\"Column '{metric_col}' must be numeric\")\n",
    "    if any(p < 0 or p > 1 for p in percentiles):\n",
    "        raise ValueError(\"Percentiles must be in [0, 1]\")\n",
    "\n",
    "    sorted_df = series.sort_values(metric_col).reset_index(drop=True)\n",
    "    N = len(sorted_df)\n",
    "    if N == 0:\n",
    "        return pd.DataFrame(columns=['movement_id', metric_col, 'percentile'])\n",
    "\n",
    "    rows = []\n",
    "    for p in percentiles:\n",
    "        idx = int(round(p * (N - 1)))\n",
    "        rows.append({\n",
    "            'movement_id': int(sorted_df.loc[idx, 'movement_id']),\n",
    "            metric_col: sorted_df.loc[idx, metric_col],\n",
    "            'percentile': p\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def plot_movement_tiles_scatter(\n",
    "    tongue_segmented: pd.DataFrame,\n",
    "    movement_ids: list,\n",
    "    x_col: str,\n",
    "    y_col: str,\n",
    "    labels: list = None,\n",
    "    color: str = 'gray',\n",
    "    s: int = 5,\n",
    "    title: str = None,\n",
    "    return_fig=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot scatter of any two kinematic columns for a given list of movement_ids.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tongue_segmented : pd.DataFrame\n",
    "        Frame-level data with at least 'movement_id', x_col, y_col.\n",
    "    movement_ids : list\n",
    "        Movement IDs to plot (one subplot per movement).\n",
    "    x_col : str\n",
    "        Column in tongue_segmented to plot on x-axis.\n",
    "    y_col : str\n",
    "        Column in tongue_segmented to plot on y-axis.\n",
    "    labels : list, optional\n",
    "        List of strings or values to annotate each subplot (same length as movement_ids).\n",
    "    color : str\n",
    "        Point color for scatter.\n",
    "    s : int\n",
    "        Point size for scatter.\n",
    "    title : str\n",
    "        Title of figure\n",
    "    \"\"\"\n",
    "    n = len(movement_ids)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(n * 2, 2), sharex=True, sharey=True)\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Global axis limits\n",
    "    all_x, all_y = [], []\n",
    "    for mid in movement_ids:\n",
    "        df = tongue_segmented[tongue_segmented['movement_id'] == mid]\n",
    "        df = df[[x_col, y_col]].dropna()\n",
    "        all_x.extend(df[x_col])\n",
    "        all_y.extend(df[y_col])\n",
    "    if not all_x:\n",
    "        raise RuntimeError(\"No valid movements found to plot.\")\n",
    "    xlim = (min(all_x), max(all_x))\n",
    "    ylim = (min(all_y), max(all_y))\n",
    "\n",
    "    for i, (ax, mid) in enumerate(zip(axes, movement_ids)):\n",
    "        df = tongue_segmented[tongue_segmented['movement_id'] == mid]\n",
    "        df = df[[x_col, y_col]].dropna()\n",
    "\n",
    "        if len(df) < 1:\n",
    "            ax.scatter([0], [0], s=10, color='black')\n",
    "        else:\n",
    "            ax.scatter(df[x_col], df[y_col], s=s, color=color)\n",
    "\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "        ax.set_xlabel(x_col, fontsize=7)\n",
    "        if ax == axes[0]:\n",
    "            ax.set_ylabel(y_col, fontsize=7)\n",
    "\n",
    "        if labels is not None:\n",
    "            ax.set_title(str(labels[i]), fontsize=8)\n",
    "    \n",
    "    if title:\n",
    "        plt.suptitle(title, fontsize=10)\n",
    "    else:\n",
    "        plt.suptitle(f\"{y_col} vs {x_col}\", fontsize=10)\n",
    "    \n",
    "    # plt.suptitle(f\"{y_col} vs {x_col}\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    if return_fig:\n",
    "        return fig\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_tongue_movement_quality(\n",
    "    kps_raw: pd.DataFrame,\n",
    "    tongue_kins: pd.DataFrame,\n",
    "    tongue_movs: pd.DataFrame,\n",
    "    nwb,\n",
    "    pred_csv: str,\n",
    "    save_dir: str,\n",
    "    percentiles: list = [0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0]\n",
    "):\n",
    "    \"\"\"\n",
    "    Analyze and visualize tongue movement quality for a single session.\n",
    "\n",
    "    Saves figures and key summary stats in a session-specific folder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tongue_kins : pd.DataFrame\n",
    "        Frame-level kinematics data.\n",
    "    tongue_movs : pd.DataFrame\n",
    "        Movement-level kinematics data (one row per movement).\n",
    "    nwb : NWB object with df_licks.\n",
    "    pred_csv : str\n",
    "        Path to the prediction CSV (used to infer session name).\n",
    "    save_dir : str\n",
    "        Directory where results will be saved.\n",
    "    percentiles : list\n",
    "        Percentiles to sample for movement quality plots.\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------\n",
    "    # Setup & Folders\n",
    "    # ----------------\n",
    "    session_id = get_session_name_from_path(str(pred_csv))\n",
    "    session_folder = os.path.join(save_dir, session_id)\n",
    "    os.makedirs(session_folder, exist_ok=True)\n",
    "\n",
    "    print(f\"Analyzing session: {session_id}\")\n",
    "    \n",
    "    # ----------------\n",
    "    # Confidence figure\n",
    "    # ----------------\n",
    "    keypt = 'tongue_tip_center'  # Example, can be parameterized in wrapper\n",
    "    plot_keypoint_confidence_analysis(\n",
    "        keypoint_dfs=kps_raw,\n",
    "        keypt=keypt,\n",
    "        save_dir=session_folder,\n",
    "        save_figures=True\n",
    "        )\n",
    "        \n",
    "    # ----------------\n",
    "    # Lick Coverage\n",
    "    # ----------------\n",
    "    total_licks = len(nwb.df_licks)\n",
    "    with_mov = nwb.df_licks['nearest_movement_id'].notna().sum()\n",
    "    coverage_pct = 100 * with_mov / total_licks if total_licks else np.nan\n",
    "\n",
    "    lick_movs = tongue_movs[tongue_movs['has_lick']]\n",
    "    lick_times = nwb.df_licks['timestamps']\n",
    "    has_mov = nwb.df_licks['nearest_movement_id'].notna()\n",
    "    covered_times = lick_times[has_mov]\n",
    "    missed_times = lick_times[~has_mov]\n",
    "\n",
    "    # ----------------\n",
    "    # Lick Coverage Figure\n",
    "    # ----------------\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(14, 8))\n",
    "    parent_gs = fig.add_gridspec(2, 1, height_ratios=[1, 1])\n",
    "    gs_top = parent_gs[0].subgridspec(1, 3, width_ratios=[0.5, 6, 3])\n",
    "    gs_bottom = parent_gs[1].subgridspec(1, 3)\n",
    "\n",
    "    ax_cov = fig.add_subplot(gs_top[0, 0])\n",
    "    ax_raster = fig.add_subplot(gs_top[0, 1])\n",
    "    ax_scat = fig.add_subplot(gs_top[0, 2])\n",
    "    ax_h0 = fig.add_subplot(gs_bottom[0, 0])\n",
    "    ax_h1 = fig.add_subplot(gs_bottom[0, 1])\n",
    "    ax_h2 = fig.add_subplot(gs_bottom[0, 2])\n",
    "\n",
    "    # --- Coverage Bar ---\n",
    "    n_missed = total_licks - with_mov\n",
    "    ax_cov.bar(0, coverage_pct, color='green', label=f'Covered (n={with_mov})')\n",
    "    ax_cov.bar(0, 100 - coverage_pct, bottom=coverage_pct,\n",
    "               color='red', label=f'Missed (n={n_missed})')\n",
    "    ax_cov.set_ylim(0, 100)\n",
    "    ax_cov.set_xticks([])\n",
    "    ax_cov.set_title(\"Lick Coverage (%)\", fontsize=10)\n",
    "    ax_cov.legend(fontsize=7, loc='lower center')\n",
    "\n",
    "    # --- Raster ---\n",
    "    ax_raster.eventplot(\n",
    "        [covered_times, missed_times],\n",
    "        lineoffsets=[1, 0], linelengths=0.8,\n",
    "        colors=['green', 'red']\n",
    "    )\n",
    "    ax_raster.set_yticks([1, 0])\n",
    "    ax_raster.set_yticklabels(['Covered', 'Missed'])\n",
    "    ax_raster.set_xlabel('Time in session (s)')\n",
    "    ax_raster.set_title('Lick coverage over session')\n",
    "\n",
    "    # --- Scatter ---\n",
    "    ax_scat.scatter(lick_movs['duration'], lick_movs['dropped_frames_pct'],\n",
    "                    alpha=0.05, edgecolor='k')\n",
    "    ax_scat.set_xlabel('Duration (s)')\n",
    "    ax_scat.set_ylabel('Dropped Frame %')\n",
    "    ax_scat.set_title('Duration vs Drop%')\n",
    "\n",
    "    # --- Histograms ---\n",
    "    ax_h0.hist(lick_movs['n_datapoints'], bins=30)\n",
    "    ax_h0.set(title='Datapoints')\n",
    "    ax_h1.hist(lick_movs['duration'], bins=30)\n",
    "    ax_h1.set(title='Duration')\n",
    "    ax_h2.hist(lick_movs['dropped_frames_pct'], bins=30)\n",
    "    ax_h2.set(title='Dropped %')\n",
    "\n",
    "    plt.suptitle(f'{session_id}', y=1.02)\n",
    "    fig.savefig(os.path.join(session_folder, \"lick_coverage_summary.png\"), dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # ----------------\n",
    "    # Movement Percentile Plots\n",
    "    # ----------------\n",
    "    tongue_kins['time_in_movement'] = (\n",
    "        tongue_kins['time'] -\n",
    "        tongue_kins.groupby('movement_id')['time'].transform('first')\n",
    "    )\n",
    "\n",
    "    percentile_results = {}\n",
    "    for metric_col in ['dropped_frames_n', 'duration']:\n",
    "        sel = select_percentile_movements(tongue_movs, metric_col=metric_col, percentiles=percentiles)\n",
    "        labels = [f\"{int(p*100)}%ile: {val:.2f}\" \n",
    "                  for p, val in zip(sel['percentile'], sel[metric_col])]\n",
    "        percentile_results[metric_col] = dict(zip(sel['percentile'], sel[metric_col]))\n",
    "\n",
    "\n",
    "        fig = plot_movement_tiles_scatter(\n",
    "            tongue_segmented=tongue_kins,\n",
    "            movement_ids=sel['movement_id'].tolist(),\n",
    "            x_col='time_in_movement',\n",
    "            y_col='x',\n",
    "            labels=labels,\n",
    "            color='gray',\n",
    "            title=metric_col,\n",
    "            return_fig=True\n",
    "        )\n",
    "        fig.savefig(os.path.join(session_folder, f\"{metric_col}_tiles.png\"), dpi=150)\n",
    "        plt.close(fig)\n",
    "\n",
    "    # ----------------\n",
    "    # Save Everything to JSON\n",
    "    # ----------------\n",
    "    results_dict = {\n",
    "        \"session_id\": session_id,\n",
    "        \"total_licks\": int(total_licks),\n",
    "        \"licks_with_movement\": int(with_mov),\n",
    "        \"coverage_pct\": float(coverage_pct),\n",
    "        \"percentiles\": percentile_results\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(session_folder, \"tongue_quality_stats.json\"), \"w\") as f:\n",
    "        json.dump(results_dict, f, indent=2)\n",
    "\n",
    "    print(f\"âœ… Finished analysis for {session_id}. Results saved to {session_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generating tongue data for session: behavior_751004_2024-12-23_14-19-57 ===\n",
      "Predictions CSV: /root/capsule/data/behavior_751004_2024-12-23_14-19-57_processed_2025-07-10_06-34-56/pred_outputs/video_preds/bottom_camera_predictions.csv\n",
      "keypoints extracted: ['nose_tip', 'jaw', 'tongue_tip_right', 'tongue_tip_center', 'tongue_tip_left', 'pointer_finger_r', 'paw_wrist_r', 'pointer_finger_l', 'paw_wrist_l', 'spout_r', 'spout_l']\n",
      "Loaded keypoints: 11 raw dataframes\n",
      "Found video CSV: /root/capsule/data/behavior_751004_2024-12-23_14-19-57/behavior-videos/bottom_camera.csv\n",
      "Video QC: Frame numbers are sequential with no gaps.\n",
      "Video QC: Timing differences are within expected range.\n",
      "keypoint_df trimmed from 3338382 to 3338381\n",
      "Synced keypoints\n",
      "Segmented 5817 unique movements\n",
      "NWB file not found for 751004 on 2024-12-23. Generating it now...\n",
      "Generated NWB file: /root/capsule/scratch/behavior_751004_2024-12-23_14-19-57/751004_2024-12-23_14-20-03.nwb\n",
      "Timestamps are adjusted such that `_in_session` timestamps start at the first go cue\n",
      "Timestamps are adjusted such that `_in_session` timestamps start at the first go cue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/aind_dynamic_foraging_data_utils/nwb_utils.py:506: UserWarning: Reward before choice time.                 This is likely due to manual rewards not being recorded in sessions from 2024\n",
      "  warnings.warn(\"Reward before choice time. \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWB load: 579 trials, 5397 licks\n",
      "Annotated kinematics with trials & licks\n",
      "Aggregated movements DF shape: (5817, 37)\n"
     ]
    }
   ],
   "source": [
    "# Path to the predictions CSV (from the processed folder)\n",
    "pred_csv = Path(\"/root/capsule/data/behavior_751004_2024-12-23_14-19-57_processed_2025-07-10_06-34-56/pred_outputs/video_preds/bottom_camera_predictions.csv\")\n",
    "\n",
    "# Root folder where the raw behavior_<...> session folders live\n",
    "data_root = Path(\"/root/capsule/data\")\n",
    "\n",
    "# save dir\n",
    "save_dir = '/root/capsule/scratch/session_analysis/'\n",
    "\n",
    "nwb, tongue_kins, tongue_movs, kps_raw = generate_tongue_dfs(pred_csv, data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_tongue_movement_quality(\n",
    "    kps_raw,\n",
    "    tongue_kins,\n",
    "    tongue_movs,\n",
    "    nwb,\n",
    "    pred_csv,\n",
    "    save_dir = save_dir,\n",
    "    percentiles=[0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_intermediate:\n",
    "    inter_folder = os.path.join(session_folder, \"intermediate_data\")\n",
    "    os.makedirs(inter_folder, exist_ok=True)\n",
    "\n",
    "    # Save kps_raw dict of DataFrames\n",
    "    for key, df in kps_raw.items():\n",
    "        df.to_parquet(os.path.join(inter_folder, f\"kps_raw_{key}.parquet\"))\n",
    "\n",
    "    # Save tongue kinematics & movements\n",
    "    tongue_kins.to_parquet(os.path.join(inter_folder, \"tongue_kins.parquet\"))\n",
    "    tongue_movs.to_parquet(os.path.join(inter_folder, \"tongue_movs.parquet\"))\n",
    "\n",
    "    # Save nwb-related DataFrames\n",
    "    nwb.df_licks.to_parquet(os.path.join(inter_folder, \"nwb_df_licks.parquet\"))\n",
    "    nwb.df_trials.to_parquet(os.path.join(inter_folder, \"nwb_df_trials.parquet\"))\n",
    "    nwb.df_events.to_parquet(os.path.join(inter_folder, \"nwb_df_events.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #script version\n",
    "\n",
    "# from aind_dynamic_foraging_behavior_video_analysis.kinematics.tongue_kinematics_utils import get_session_name_from_path\n",
    "\n",
    "# session_id = get_session_name_from_path(str(pred_csv))\n",
    "\n",
    "# # --- coverage calculations ---\n",
    "# total_licks = len(nwb.df_licks)\n",
    "# with_mov = nwb.df_licks['nearest_movement_id'].notna().sum()\n",
    "# coverage_pct = 100 * with_mov / total_licks if total_licks else np.nan\n",
    "\n",
    "# lick_movs = tongue_movs[tongue_movs['has_lick']]\n",
    "# lick_times = nwb.df_licks['timestamps']  # or time_in_session\n",
    "# has_mov = nwb.df_licks['nearest_movement_id'].notna()\n",
    "# covered_times = lick_times[has_mov]\n",
    "# missed_times = lick_times[~has_mov]\n",
    "\n",
    "# # --- FIGURE 1 ---\n",
    "# fig = plt.figure(constrained_layout=True, figsize=(14, 8))\n",
    "# parent_gs = fig.add_gridspec(2, 1, height_ratios=[1, 1])  # top row, bottom row\n",
    "\n",
    "# # Top row: skinny coverage, wide raster, scatter\n",
    "# gs_top = parent_gs[0].subgridspec(1, 4, width_ratios=[0.5, 2.5, 2.0, 2.0])\n",
    "# gs_top = parent_gs[0].subgridspec(1, 3, width_ratios=[0.5, 6, 3])\n",
    "\n",
    "\n",
    "# # Bottom row: 3 equal-width histograms\n",
    "# gs_bottom = parent_gs[1].subgridspec(1, 3, width_ratios=[1, 1, 1])\n",
    "\n",
    "# # --- AXES ---\n",
    "# ax_cov = fig.add_subplot(gs_top[0, 0])\n",
    "# ax_raster = fig.add_subplot(gs_top[0, 1])\n",
    "# ax_scat = fig.add_subplot(gs_top[0, 2])\n",
    "# ax_h0 = fig.add_subplot(gs_bottom[0, 0])\n",
    "# ax_h1 = fig.add_subplot(gs_bottom[0, 1])\n",
    "# ax_h2 = fig.add_subplot(gs_bottom[0, 2])\n",
    "\n",
    "# # --- COVERAGE BAR (stacked, with n in legend) ---\n",
    "# n_missed = total_licks - with_mov\n",
    "# ax_cov.bar(0, coverage_pct, color='green', label=f'Covered (n={with_mov})')\n",
    "# ax_cov.bar(0, 100 - coverage_pct, bottom=coverage_pct,\n",
    "#            color='red', label=f'Missed (n={n_missed})')\n",
    "\n",
    "# ax_cov.set_ylim(0, 100)\n",
    "# ax_cov.set_xlim(-0.5, 0.5)\n",
    "# ax_cov.set_xticks([])\n",
    "# ax_cov.set_yticks([0, 50, 100])\n",
    "# ax_cov.set_ylabel('percentage')\n",
    "# ax_cov.set_title(\"Lick Coverage (%)\", fontsize=10)\n",
    "# ax_cov.legend(fontsize=7, loc='lower center')\n",
    "\n",
    "\n",
    "# # --- RASTER ---\n",
    "# ax_raster.eventplot(\n",
    "#     [covered_times, missed_times],\n",
    "#     lineoffsets=[1, 0], linelengths=0.8,\n",
    "#     colors=['green', 'red']\n",
    "# )\n",
    "# ax_raster.set_yticks([1, 0])\n",
    "# ax_raster.set_yticklabels(['Covered', 'Missed'])\n",
    "# ax_raster.set_xlabel('Time in session (s)')\n",
    "# ax_raster.set_title(f'Lick coverage over session')\n",
    "\n",
    "# # --- SCATTER ---\n",
    "# ax_scat.scatter(lick_movs['duration'], lick_movs['dropped_frames_pct'],\n",
    "#                 alpha=0.05, edgecolor='k')\n",
    "# ax_scat.set_xlabel('Duration (s)')\n",
    "# ax_scat.set_ylabel('Dropped Frame %')\n",
    "# ax_scat.set_title('Duration vs Drop%')\n",
    "\n",
    "# # --- HISTOGRAMS ---\n",
    "# ax_h0.hist(lick_movs['n_datapoints'], bins=30)\n",
    "# ax_h0.set(title='Datapoints', xlabel='number of datapoints in movement', ylabel='count')\n",
    "\n",
    "# ax_h1.hist(lick_movs['duration'], bins=30)\n",
    "# ax_h1.set(title='Duration', xlabel='duration of movement (s)')\n",
    "\n",
    "# ax_h2.hist(lick_movs['dropped_frames_pct'], bins=30)\n",
    "# ax_h2.set(title='Dropped %', xlabel='percentage dropped frames (%)')\n",
    "\n",
    "# plt.suptitle(f'{session_id}', y=1.05)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # --- FIGURE 2 and 3: EXAMPLE MOVEMENTS ---\n",
    "\n",
    "# # relative time for plotting example movements\n",
    "# tongue_kins['time_in_movement'] = (\n",
    "#     tongue_kins['time'] - \n",
    "#     tongue_kins.groupby('movement_id')['time'].transform('first')\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# percentiles=[0,.1,.25,.5,.75,.9,1]\n",
    "\n",
    "# metric_col = 'dropped_frames_n'\n",
    "# sel = select_percentile_movements(tongue_movs, metric_col=metric_col,percentiles=percentiles)\n",
    "# labels = [f\"{int(p*100)}%ile: {val:.2f}\" \n",
    "#           for p, val in zip(sel['percentile'], sel[metric_col])]\n",
    "# plot_movement_tiles_scatter(\n",
    "#     tongue_segmented=tongue_kins,\n",
    "#     movement_ids=sel['movement_id'].tolist(),\n",
    "#     x_col='time_in_movement',\n",
    "#     y_col='x',\n",
    "#     labels=labels,\n",
    "#     color='gray',\n",
    "#     title=metric_col\n",
    "# )\n",
    "\n",
    "\n",
    "# metric_col = 'duration'\n",
    "# sel = select_percentile_movements(tongue_movs, metric_col=metric_col,percentiles=percentiles)\n",
    "# labels = [f\"{int(p*100)}%ile: {val:.2f}\" \n",
    "#           for p, val in zip(sel['percentile'], sel[metric_col])]\n",
    "\n",
    "# plot_movement_tiles_scatter(\n",
    "#     tongue_segmented=tongue_kins,\n",
    "#     movement_ids=sel['movement_id'].tolist(),\n",
    "#     x_col='time_in_movement',\n",
    "#     y_col='x',\n",
    "#     labels=labels,\n",
    "#     color='gray',\n",
    "#     title=metric_col\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentiles=[0,.1,.25,.5,.75,.9,1]\n",
    "\n",
    "# metric_col = 'dropped_frames_n'\n",
    "# sel = select_percentile_movements(tongue_movs, metric_col=metric_col,percentiles=percentiles)\n",
    "# labels = [f\"{int(p*100)}%ile: {val:.2f}\" \n",
    "#           for p, val in zip(sel['percentile'], sel[metric_col])]\n",
    "# plot_movement_tiles_scatter(\n",
    "#     tongue_segmented=tongue_kins,\n",
    "#     movement_ids=sel['movement_id'].tolist(),\n",
    "#     x_col='time_in_movement',\n",
    "#     y_col='x',\n",
    "#     labels=labels,\n",
    "#     color='gray',\n",
    "#     title=metric_col\n",
    "# )\n",
    "\n",
    "\n",
    "# metric_col = 'duration'\n",
    "# sel = select_percentile_movements(tongue_movs, metric_col=metric_col,percentiles=percentiles)\n",
    "# labels = [f\"{int(p*100)}%ile: {val:.2f}\" \n",
    "#           for p, val in zip(sel['percentile'], sel[metric_col])]\n",
    "\n",
    "# plot_movement_tiles_scatter(\n",
    "#     tongue_segmented=tongue_kins,\n",
    "#     movement_ids=sel['movement_id'].tolist(),\n",
    "#     x_col='time_in_movement',\n",
    "#     y_col='x',\n",
    "#     labels=labels,\n",
    "#     color='gray',\n",
    "#     title=metric_col\n",
    "# )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
