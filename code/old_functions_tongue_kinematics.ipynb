{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.9/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.9/site-packages (from opencv-python) (2.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in /opt/conda/lib/python3.9/site-packages (2.1.2)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.9/site-packages (from moviepy) (2.37.0)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in /opt/conda/lib/python3.9/site-packages (from moviepy) (1.0.1)\n",
      "Requirement already satisfied: pillow<11.0,>=9.2.0 in /opt/conda/lib/python3.9/site-packages (from moviepy) (10.3.0)\n",
      "Requirement already satisfied: numpy>=1.25.0 in /opt/conda/lib/python3.9/site-packages (from moviepy) (2.0.2)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in /opt/conda/lib/python3.9/site-packages (from moviepy) (5.1.1)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /opt/conda/lib/python3.9/site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /opt/conda/lib/python3.9/site-packages (from moviepy) (0.6.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from proglog<=1.0.0->moviepy) (4.63.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from moviepy import VideoFileClip\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import os\n",
    "\n",
    "\n",
    "def create_labeled_video(\n",
    "    clip: VideoFileClip,\n",
    "    xs_arr: np.ndarray,\n",
    "    ys_arr: np.ndarray,\n",
    "    mask_array: Optional[np.ndarray] = None,\n",
    "    dotsize: int = 4,\n",
    "    colormap: str = \"cool\",\n",
    "    fps: Optional[float] = None,\n",
    "    filename: str = \"movie.mp4\",\n",
    "    start_time: float = 0.0,\n",
    ") -> None:\n",
    "    \"\"\"Helper function for creating annotated videos.\n",
    "\n",
    "    Args\n",
    "        clip\n",
    "        xs_arr: shape T x n_joints\n",
    "        ys_arr: shape T x n_joints\n",
    "        mask_array: shape T x n_joints; timepoints/joints with a False entry will not be plotted\n",
    "        dotsize: size of marker dot on labeled video\n",
    "        colormap: matplotlib color map for markers\n",
    "        fps: None to default to fps of original video\n",
    "        filename: video file name\n",
    "        start_time: time (in seconds) of video start\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if mask_array is None:\n",
    "        mask_array = ~np.isnan(xs_arr)\n",
    "\n",
    "    n_frames, n_keypoints = xs_arr.shape\n",
    "\n",
    "    # set colormap for each color\n",
    "    colors = make_cmap(n_keypoints, cmap=colormap)\n",
    "\n",
    "    # extract info from clip\n",
    "    nx, ny = clip.size\n",
    "    dur = int(clip.duration - clip.start)\n",
    "    fps_og = clip.fps\n",
    "\n",
    "    # upsample clip if low resolution; need to do this for dots and text to look nice\n",
    "    if nx <= 100 or ny <= 100:\n",
    "        upsample_factor = 2.5\n",
    "    elif nx <= 192 or ny <= 192:\n",
    "        upsample_factor = 2\n",
    "    else:\n",
    "        upsample_factor = 1\n",
    "\n",
    "    if upsample_factor > 1:\n",
    "        clip = clip.resize((upsample_factor * nx, upsample_factor * ny))\n",
    "        nx, ny = clip.size\n",
    "\n",
    "    print(f\"Duration of video [s]: {np.round(dur, 2)}, recorded at {np.round(fps_og, 2)} fps!\")\n",
    "\n",
    "    def seconds_to_hms(seconds):\n",
    "        # Convert seconds to a timedelta object\n",
    "        td = datetime.timedelta(seconds=seconds)\n",
    "\n",
    "        # Extract hours, minutes, and seconds from the timedelta object\n",
    "        hours = td // datetime.timedelta(hours=1)\n",
    "        minutes = (td // datetime.timedelta(minutes=1)) % 60\n",
    "        seconds = td % datetime.timedelta(minutes=1)\n",
    "\n",
    "        # Format the hours, minutes, and seconds into a string\n",
    "        hms_str = f\"{hours:02}:{minutes:02}:{seconds.seconds:02}\"\n",
    "\n",
    "        return hms_str\n",
    "\n",
    "    # add marker to each frame t, where t is in sec\n",
    "    def add_marker_and_timestamps(get_frame, t):\n",
    "        image = get_frame(t * 1.0)\n",
    "        # frame [ny x ny x 3]\n",
    "        frame = image.copy()\n",
    "        # convert from sec to indices\n",
    "        index = int(np.round(t * 1.0 * fps_og))\n",
    "        # ----------------\n",
    "        # markers\n",
    "        # ----------------\n",
    "        for bpindex in range(n_keypoints):\n",
    "            if index >= n_frames:\n",
    "                print(\"Skipped frame {}, marker {}\".format(index, bpindex))\n",
    "                continue\n",
    "            if mask_array[index, bpindex]:\n",
    "                xc = min(int(upsample_factor * xs_arr[index, bpindex]), nx - 1)\n",
    "                yc = min(int(upsample_factor * ys_arr[index, bpindex]), ny - 1)\n",
    "                frame = cv2.circle(\n",
    "                    frame,\n",
    "                    center=(xc, yc),\n",
    "                    radius=dotsize,\n",
    "                    color=colors[bpindex].tolist(),\n",
    "                    thickness=-1,\n",
    "                )\n",
    "        # ----------------\n",
    "        # timestamps\n",
    "        # ----------------\n",
    "        seconds_from_start = t + start_time\n",
    "        time_from_start = seconds_to_hms(seconds_from_start)\n",
    "        idx_from_start = int(np.round(seconds_from_start * 1.0 * fps_og))\n",
    "        text = f\"t={time_from_start}, frame={idx_from_start}\"\n",
    "        # define text info\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 0.5\n",
    "        font_thickness = 1\n",
    "        # calculate the size of the text\n",
    "        text_size = cv2.getTextSize(text, font, font_scale, font_thickness)[0]\n",
    "        # calculate the position of the text in the upper-left corner\n",
    "        offset = 6\n",
    "        text_x = offset  # offset from the left\n",
    "        text_y = text_size[1] + offset  # offset from the bottom\n",
    "        # make black rectangle with a small padding of offset / 2 pixels\n",
    "        cv2.rectangle(\n",
    "            frame,\n",
    "            (text_x - int(offset / 2), text_y + int(offset / 2)),\n",
    "            (text_x + text_size[0] + int(offset / 2), text_y - text_size[1] - int(offset / 2)),\n",
    "            (0, 0, 0),  # rectangle color\n",
    "            cv2.FILLED,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            text,\n",
    "            (text_x, text_y),\n",
    "            font,\n",
    "            font_scale,\n",
    "            (255, 255, 255),  # font color\n",
    "            font_thickness,\n",
    "            lineType=cv2.LINE_AA,\n",
    "        )\n",
    "        return frame\n",
    "\n",
    "    clip_marked = clip.fl(add_marker_and_timestamps)\n",
    "    clip_marked.write_videofile(filename, codec=\"libx264\")\n",
    "    clip_marked.close()\n",
    "\n",
    "\n",
    "def make_cmap(number_colors: int, cmap: str = \"cool\"):\n",
    "    color_class = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    C = color_class.to_rgba(np.linspace(0, 1, number_colors))\n",
    "    colors = (C[:, :3] * 255).astype(np.uint8)\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def extract_clips_ffmpeg_after_reencode(input_video_path, timestamps, clip_length, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for idx, start_time in enumerate(timestamps):\n",
    "        end_time = start_time + clip_length\n",
    "        input_basename_ext = os.path.basename(input_video_path)\n",
    "        input_basename, _ = os.path.splitext(input_basename_ext)\n",
    "        output_filename = input_basename + f\"_clip_{idx+1}_{start_time:.2f}s_to_{end_time:.2f}s.mp4\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "        if os.path.isfile(output_path):\n",
    "            continue\n",
    "\n",
    "        command = [\n",
    "            'ffmpeg',\n",
    "            '-ss', str(start_time),\n",
    "            '-i', input_video_path,\n",
    "            '-t', str(clip_length),\n",
    "            '-c', 'copy',             # Copy codec (no re-encoding)\n",
    "            output_path\n",
    "        ]\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"Clip saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def process_and_label_clips(input_video_path, df, timestamps, clip_length, output_dir, labeled_output_dir):\n",
    "    # Step 1: Extract clips using your provided function\n",
    "    extract_clips_ffmpeg_after_reencode(input_video_path, timestamps, clip_length, output_dir)\n",
    "    \n",
    "    # Ensure output directories exist for labeled videos\n",
    "    if not os.path.exists(labeled_output_dir):\n",
    "        os.makedirs(labeled_output_dir)\n",
    "    \n",
    "    # Step 2: Process each clip\n",
    "    for idx, start_time in enumerate(timestamps):\n",
    "        # Construct clip filename (must match the naming in extract_clips_ffmpeg_after_reencode)\n",
    "        input_basename = os.path.splitext(os.path.basename(input_video_path))[0]\n",
    "        clip_filename = os.path.join(\n",
    "            output_dir, \n",
    "            f\"{input_basename}_clip_{idx+1}_{start_time:.2f}s_to_{start_time+clip_length:.2f}s.mp4\"\n",
    "        )\n",
    "        \n",
    "        if not os.path.isfile(clip_filename):\n",
    "            print(f\"Clip file {clip_filename} not found, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Step 3: Load the clip using MoviePy\n",
    "        clip = VideoFileClip(clip_filename)\n",
    "        \n",
    "        # Step 4: Filter the DataFrame to get tracking data for this clip\n",
    "        # Assuming df['time'] is in seconds\n",
    "        df_clip = df[(df['time'] >= start_time) & (df['time'] < start_time + clip_length)]\n",
    "        \n",
    "        # Convert tracking data to NumPy arrays. Here, we assume one keypoint per frame.\n",
    "        # If you have multiple keypoints per frame, adjust the reshaping accordingly.\n",
    "        xs_arr = df_clip['x'].to_numpy().reshape(-1, 1)  # shape: (T, 1)\n",
    "        ys_arr = df_clip['y'].to_numpy().reshape(-1, 1)  # shape: (T, 1)\n",
    "        \n",
    "        # Create a mask for valid (non-NaN) values\n",
    "        mask_array = ~np.isnan(xs_arr)\n",
    "        \n",
    "        # Step 5: Define output path for the labeled video\n",
    "        labeled_filename = os.path.join(\n",
    "            labeled_output_dir,\n",
    "            f\"labeled_clip_{idx+1}_{start_time:.2f}s_to_{start_time+clip_length:.2f}s.mp4\"\n",
    "        )\n",
    "        \n",
    "        # Step 6: Label the clip\n",
    "        create_labeled_video(\n",
    "            clip=clip,\n",
    "            xs_arr=xs_arr,\n",
    "            ys_arr=ys_arr,\n",
    "            mask_array=mask_array,\n",
    "            filename=labeled_filename,\n",
    "            start_time=start_time\n",
    "        )\n",
    "        \n",
    "        # Close the clip to free resources\n",
    "        clip.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2808/838475983.py:1: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_test = pd.read_csv('/root/capsule/data/BottomViewPylon1-MIB-2025-02-17/inference/behavior_716325_2024-05-31_10-31-14/bottom_camera.csv')\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('/root/capsule/data/BottomViewPylon1-MIB-2025-02-17/inference/behavior_716325_2024-05-31_10-31-14/bottom_camera.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = df_test[2:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2 = pd.read_csv('/root/capsule/data/BottomViewPylon1-MIB-2025-02-17/inference/behavior_716325_2024-05-31_10-31-14/bottom_camera.csv',header=[0,1,2],index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scorer</th>\n",
       "      <th>heatmap_tracker</th>\n",
       "      <th>heatmap_tracker.1</th>\n",
       "      <th>heatmap_tracker.2</th>\n",
       "      <th>heatmap_tracker.3</th>\n",
       "      <th>heatmap_tracker.4</th>\n",
       "      <th>heatmap_tracker.5</th>\n",
       "      <th>heatmap_tracker.6</th>\n",
       "      <th>heatmap_tracker.7</th>\n",
       "      <th>heatmap_tracker.8</th>\n",
       "      <th>...</th>\n",
       "      <th>heatmap_tracker.23</th>\n",
       "      <th>heatmap_tracker.24</th>\n",
       "      <th>heatmap_tracker.25</th>\n",
       "      <th>heatmap_tracker.26</th>\n",
       "      <th>heatmap_tracker.27</th>\n",
       "      <th>heatmap_tracker.28</th>\n",
       "      <th>heatmap_tracker.29</th>\n",
       "      <th>heatmap_tracker.30</th>\n",
       "      <th>heatmap_tracker.31</th>\n",
       "      <th>heatmap_tracker.32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>515.850830078125</td>\n",
       "      <td>333.6799011230469</td>\n",
       "      <td>0.9987945556640625</td>\n",
       "      <td>335.4886474609375</td>\n",
       "      <td>322.27191162109375</td>\n",
       "      <td>0.999667763710022</td>\n",
       "      <td>355.119140625</td>\n",
       "      <td>266.0167236328125</td>\n",
       "      <td>0.00017966664745472372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00016898527974262834</td>\n",
       "      <td>355.7112731933594</td>\n",
       "      <td>269.715576171875</td>\n",
       "      <td>0.0001567225845064968</td>\n",
       "      <td>352.0434875488281</td>\n",
       "      <td>250.73495483398438</td>\n",
       "      <td>0.9971842765808105</td>\n",
       "      <td>362.0303955078125</td>\n",
       "      <td>387.4951171875</td>\n",
       "      <td>0.9979580044746399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>516.1701049804688</td>\n",
       "      <td>335.2160949707031</td>\n",
       "      <td>0.9981264472007751</td>\n",
       "      <td>335.70782470703125</td>\n",
       "      <td>322.0995788574219</td>\n",
       "      <td>0.999774158000946</td>\n",
       "      <td>355.1353454589844</td>\n",
       "      <td>265.5116271972656</td>\n",
       "      <td>0.00017797944019548595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00017053421470336616</td>\n",
       "      <td>355.8164978027344</td>\n",
       "      <td>269.76177978515625</td>\n",
       "      <td>0.00015676190378144383</td>\n",
       "      <td>352.457763671875</td>\n",
       "      <td>250.5872039794922</td>\n",
       "      <td>0.9968073964118958</td>\n",
       "      <td>361.8670654296875</td>\n",
       "      <td>387.4626770019531</td>\n",
       "      <td>0.9985958337783813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>516.1206665039062</td>\n",
       "      <td>335.470458984375</td>\n",
       "      <td>0.9993218183517456</td>\n",
       "      <td>335.676513671875</td>\n",
       "      <td>321.9776306152344</td>\n",
       "      <td>0.9998406767845154</td>\n",
       "      <td>355.12109375</td>\n",
       "      <td>265.642333984375</td>\n",
       "      <td>0.00018064581672661006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00017063436098396778</td>\n",
       "      <td>355.53289794921875</td>\n",
       "      <td>269.7445373535156</td>\n",
       "      <td>0.00015661929501220584</td>\n",
       "      <td>352.4293518066406</td>\n",
       "      <td>250.6887664794922</td>\n",
       "      <td>0.9966299533843994</td>\n",
       "      <td>361.6092834472656</td>\n",
       "      <td>387.4251403808594</td>\n",
       "      <td>0.9990935325622559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>516.2051391601562</td>\n",
       "      <td>335.7549133300781</td>\n",
       "      <td>0.9991072416305542</td>\n",
       "      <td>335.9415283203125</td>\n",
       "      <td>322.1065979003906</td>\n",
       "      <td>0.9996438026428223</td>\n",
       "      <td>355.2342224121094</td>\n",
       "      <td>265.6594543457031</td>\n",
       "      <td>0.00017980656411964446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00017180232680402696</td>\n",
       "      <td>355.35760498046875</td>\n",
       "      <td>269.7208557128906</td>\n",
       "      <td>0.0001566487189847976</td>\n",
       "      <td>352.66864013671875</td>\n",
       "      <td>250.59262084960938</td>\n",
       "      <td>0.995743453502655</td>\n",
       "      <td>361.713134765625</td>\n",
       "      <td>387.47637939453125</td>\n",
       "      <td>0.9988307952880859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>516.283203125</td>\n",
       "      <td>335.7440185546875</td>\n",
       "      <td>0.9988868832588196</td>\n",
       "      <td>335.6446533203125</td>\n",
       "      <td>321.9900817871094</td>\n",
       "      <td>0.9998456239700317</td>\n",
       "      <td>355.1673583984375</td>\n",
       "      <td>265.5515441894531</td>\n",
       "      <td>0.00018082704627886415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00017130440392065793</td>\n",
       "      <td>355.5014343261719</td>\n",
       "      <td>269.7889709472656</td>\n",
       "      <td>0.00015657953917980194</td>\n",
       "      <td>352.4853210449219</td>\n",
       "      <td>250.59580993652344</td>\n",
       "      <td>0.9969454407691956</td>\n",
       "      <td>361.7376708984375</td>\n",
       "      <td>387.55853271484375</td>\n",
       "      <td>0.9988279342651367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  scorer    heatmap_tracker  heatmap_tracker.1   heatmap_tracker.2  \\\n",
       "0      0   515.850830078125  333.6799011230469  0.9987945556640625   \n",
       "1      1  516.1701049804688  335.2160949707031  0.9981264472007751   \n",
       "2      2  516.1206665039062   335.470458984375  0.9993218183517456   \n",
       "3      3  516.2051391601562  335.7549133300781  0.9991072416305542   \n",
       "4      4      516.283203125  335.7440185546875  0.9988868832588196   \n",
       "\n",
       "    heatmap_tracker.3   heatmap_tracker.4   heatmap_tracker.5  \\\n",
       "0   335.4886474609375  322.27191162109375   0.999667763710022   \n",
       "1  335.70782470703125   322.0995788574219   0.999774158000946   \n",
       "2    335.676513671875   321.9776306152344  0.9998406767845154   \n",
       "3   335.9415283203125   322.1065979003906  0.9996438026428223   \n",
       "4   335.6446533203125   321.9900817871094  0.9998456239700317   \n",
       "\n",
       "   heatmap_tracker.6  heatmap_tracker.7       heatmap_tracker.8  ...  \\\n",
       "0      355.119140625  266.0167236328125  0.00017966664745472372  ...   \n",
       "1  355.1353454589844  265.5116271972656  0.00017797944019548595  ...   \n",
       "2       355.12109375   265.642333984375  0.00018064581672661006  ...   \n",
       "3  355.2342224121094  265.6594543457031  0.00017980656411964446  ...   \n",
       "4  355.1673583984375  265.5515441894531  0.00018082704627886415  ...   \n",
       "\n",
       "       heatmap_tracker.23  heatmap_tracker.24  heatmap_tracker.25  \\\n",
       "0  0.00016898527974262834   355.7112731933594    269.715576171875   \n",
       "1  0.00017053421470336616   355.8164978027344  269.76177978515625   \n",
       "2  0.00017063436098396778  355.53289794921875   269.7445373535156   \n",
       "3  0.00017180232680402696  355.35760498046875   269.7208557128906   \n",
       "4  0.00017130440392065793   355.5014343261719   269.7889709472656   \n",
       "\n",
       "       heatmap_tracker.26  heatmap_tracker.27  heatmap_tracker.28  \\\n",
       "0   0.0001567225845064968   352.0434875488281  250.73495483398438   \n",
       "1  0.00015676190378144383    352.457763671875   250.5872039794922   \n",
       "2  0.00015661929501220584   352.4293518066406   250.6887664794922   \n",
       "3   0.0001566487189847976  352.66864013671875  250.59262084960938   \n",
       "4  0.00015657953917980194   352.4853210449219  250.59580993652344   \n",
       "\n",
       "   heatmap_tracker.29 heatmap_tracker.30  heatmap_tracker.31  \\\n",
       "0  0.9971842765808105  362.0303955078125      387.4951171875   \n",
       "1  0.9968073964118958  361.8670654296875   387.4626770019531   \n",
       "2  0.9966299533843994  361.6092834472656   387.4251403808594   \n",
       "3   0.995743453502655   361.713134765625  387.47637939453125   \n",
       "4  0.9969454407691956  361.7376708984375  387.55853271484375   \n",
       "\n",
       "   heatmap_tracker.32  \n",
       "0  0.9979580044746399  \n",
       "1  0.9985958337783813  \n",
       "2  0.9990935325622559  \n",
       "3  0.9988307952880859  \n",
       "4  0.9988279342651367  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from LP to make video\n",
    "os.makedirs(os.path.dirname('/root/capsule/scratch/clips_for_labeling/labeled/'), exist_ok=True)\n",
    "# transform df to numpy array\n",
    "\n",
    "# get LP data\n",
    "\n",
    "# Load the CSV file into a DataFrame -- my version if needed\n",
    "# keypoint_dfs = load_keypoints_from_csv('/root/capsule/data/matt_test_DLC_LP_results_20240902/outputs/video_preds2/bottom_camera.csv')\n",
    "# print(keypoint_dfs.keys())\n",
    "\n",
    "# version copied from LP scripts from Di\n",
    "header_rows = [0, 1, 2]\n",
    "gt_df = pd.read_csv('/root/capsule/data/BottomViewPylon1-MIB-2025-02-17/inference/behavior_716325_2024-05-31_10-31-14/bottom_camera.csv', header=header_rows, index_col=0)\n",
    "\n",
    "# LP code\n",
    "keypoints_arr = np.reshape(gt_df.to_numpy(), [gt_df.shape[0], -1, 3])\n",
    "xs_arr = keypoints_arr[:, :, 0]\n",
    "ys_arr = keypoints_arr[:, :, 1]\n",
    "mask_array = keypoints_arr[:, :, 2] > 0.8\n",
    "# video generation\n",
    "video_clip = VideoFileClip('/root/capsule/data/matt_test_DLC_LP_results_20240902/video_predictonly/bottom_camera.mp4')\n",
    "create_labeled_video(\n",
    "    clip=video_clip,\n",
    "    xs_arr=xs_arr,\n",
    "    ys_arr=ys_arr,\n",
    "    mask_array=mask_array,\n",
    "    filename='/root/capsule/scratch/bottom_camera_labeled.mp4',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5.15850830e+02, 3.33679901e+02, 9.98794556e-01],\n",
       "        [3.35488647e+02, 3.22271912e+02, 9.99667764e-01],\n",
       "        [3.55119141e+02, 2.66016724e+02, 1.79666647e-04],\n",
       "        ...,\n",
       "        [3.55711273e+02, 2.69715576e+02, 1.56722585e-04],\n",
       "        [3.52043488e+02, 2.50734955e+02, 9.97184277e-01],\n",
       "        [3.62030396e+02, 3.87495117e+02, 9.97958004e-01]],\n",
       "\n",
       "       [[5.16170105e+02, 3.35216095e+02, 9.98126447e-01],\n",
       "        [3.35707825e+02, 3.22099579e+02, 9.99774158e-01],\n",
       "        [3.55135345e+02, 2.65511627e+02, 1.77979440e-04],\n",
       "        ...,\n",
       "        [3.55816498e+02, 2.69761780e+02, 1.56761904e-04],\n",
       "        [3.52457764e+02, 2.50587204e+02, 9.96807396e-01],\n",
       "        [3.61867065e+02, 3.87462677e+02, 9.98595834e-01]],\n",
       "\n",
       "       [[5.16120667e+02, 3.35470459e+02, 9.99321818e-01],\n",
       "        [3.35676514e+02, 3.21977631e+02, 9.99840677e-01],\n",
       "        [3.55121094e+02, 2.65642334e+02, 1.80645817e-04],\n",
       "        ...,\n",
       "        [3.55532898e+02, 2.69744537e+02, 1.56619295e-04],\n",
       "        [3.52429352e+02, 2.50688766e+02, 9.96629953e-01],\n",
       "        [3.61609283e+02, 3.87425140e+02, 9.99093533e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[5.15014587e+02, 3.30774353e+02, 9.99243677e-01],\n",
       "        [3.38512115e+02, 3.21312927e+02, 9.98203278e-01],\n",
       "        [3.55453888e+02, 2.65691528e+02, 1.90371909e-04],\n",
       "        ...,\n",
       "        [3.56433655e+02, 2.69575897e+02, 1.56567810e-04],\n",
       "        [3.54367004e+02, 2.50246597e+02, 9.96380329e-01],\n",
       "        [3.61440155e+02, 3.88554077e+02, 9.97205079e-01]],\n",
       "\n",
       "       [[5.15046082e+02, 3.30774536e+02, 9.99235749e-01],\n",
       "        [3.38471008e+02, 3.21354309e+02, 9.99990225e-01],\n",
       "        [3.55359833e+02, 2.65753418e+02, 1.90164574e-04],\n",
       "        ...,\n",
       "        [3.56434723e+02, 2.69515259e+02, 1.56580354e-04],\n",
       "        [3.54239807e+02, 2.50296326e+02, 9.97102916e-01],\n",
       "        [3.61495850e+02, 3.88512665e+02, 9.97443974e-01]],\n",
       "\n",
       "       [[5.14885681e+02, 3.30711273e+02, 9.99419272e-01],\n",
       "        [3.38447449e+02, 3.21353058e+02, 9.99989986e-01],\n",
       "        [3.55168488e+02, 2.65722260e+02, 1.91625732e-04],\n",
       "        ...,\n",
       "        [3.56533539e+02, 2.69588531e+02, 1.56556503e-04],\n",
       "        [3.54216705e+02, 2.50321533e+02, 9.97206748e-01],\n",
       "        [3.61469940e+02, 3.88540070e+02, 9.97272372e-01]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version copied from LP scripts from Di\n",
    "header_rows = [0, 1, 2]\n",
    "gt_df = pd.read_csv('/root/capsule/data/BottomViewPylon1-MIB-2025-02-17/inference/behavior_716325_2024-05-31_10-31-14/bottom_camera.csv', header=header_rows, index_col=0)\n",
    "\n",
    "# LP code\n",
    "keypoints_arr = np.reshape(gt_df.to_numpy(), [gt_df.shape[0], -1, 3])\n",
    "keypoints_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2689719, 11, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(keypoints_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_label_clips(input_video_path, timestamps, clip_length, clip_output_dir, label_output_dir, keypoint_dataframes):\n",
    "    # Step 1: Extract clips\n",
    "    extract_clips_ffmpeg_after_reencode(input_video_path, timestamps, clip_length, clip_output_dir)\n",
    "    \n",
    "    # For each timestamp/clip\n",
    "    for idx, start_time in enumerate(timestamps):\n",
    "        # Construct expected clip filename (should match the naming scheme in your extract function)\n",
    "        input_basename_ext = os.path.basename(input_video_path)\n",
    "        input_basename, _ = os.path.splitext(input_basename_ext)\n",
    "        clip_filename = f\"{input_basename}_clip_{idx+1}_{start_time:.2f}s_to_{start_time+clip_length:.2f}s.mp4\"\n",
    "        clip_path = os.path.join(clip_output_dir, clip_filename)\n",
    "        \n",
    "        # Load the clip\n",
    "        clip = VideoFileClip(clip_path)\n",
    "        \n",
    "        # Step 2 & 3: Build xs_arr and ys_arr for the clip\n",
    "        # We assume each dataframe's 'time' column is in seconds relative to the original video.\n",
    "        xs_list = []\n",
    "        ys_list = []\n",
    "        for key, df in keypoint_dataframes.items():\n",
    "            # Filter the dataframe for the clip’s time window.\n",
    "            # You might need to adjust tolerance if your times are not perfectly aligned.\n",
    "            clip_df = df[(df['time'] >= start_time) & (df['time'] < start_time + clip_length)]\n",
    "            \n",
    "            # Here, we assume one row per frame. \n",
    "            # If the number of rows doesn't match the number of frames in the clip,\n",
    "            # you could resample or interpolate the keypoint positions.\n",
    "            xs_list.append(clip_df['x'].to_numpy())\n",
    "            ys_list.append(clip_df['y'].to_numpy())\n",
    "        \n",
    "        # Convert lists to 2D arrays: each column corresponds to a keypoint.\n",
    "        # (This requires that all keypoint arrays have the same length.)\n",
    "        xs_arr = np.column_stack(xs_list)\n",
    "        ys_arr = np.column_stack(ys_list)\n",
    "        \n",
    "        # Optional: Verify that xs_arr.shape[0] (number of timepoints) matches expected frame count.\n",
    "        expected_frames = int(clip.fps * clip.duration)\n",
    "        if xs_arr.shape[0] != expected_frames:\n",
    "            print(f\"Warning: Number of keypoint frames ({xs_arr.shape[0]}) does not match video frames ({expected_frames}).\")\n",
    "            # You could add interpolation or padding here if needed.\n",
    "        \n",
    "        # Step 4: Create labeled video for this clip\n",
    "        labeled_clip_filename = f\"{input_basename}_clip_{idx+1}_{start_time:.2f}s_to_{start_time+clip_length:.2f}s_labeled.mp4\"\n",
    "        labeled_clip_path = os.path.join(label_output_dir, labeled_clip_filename)\n",
    "        \n",
    "        create_labeled_video(clip, xs_arr, ys_arr, filename=labeled_clip_path, start_time=start_time)\n",
    "        clip.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def segment_movements(df, max_dropped_frames=3):\n",
    "#     segments = []\n",
    "#     current_segment = []\n",
    "#     nan_counter = 0\n",
    "    \n",
    "#     for i, row in df.iterrows():\n",
    "#         if pd.isna(row['x']) or pd.isna(row['y']):  # Object not detected\n",
    "#             nan_counter += 1\n",
    "#         else:  # Object detected\n",
    "#             nan_counter = 0\n",
    "            \n",
    "#         if nan_counter <= max_dropped_frames:  # Allowable dropped frames\n",
    "#             current_segment.append(row)\n",
    "#         else:\n",
    "#             if current_segment:  # Save the current segment\n",
    "#                 segments.append(pd.DataFrame(current_segment))\n",
    "#                 current_segment = []  # Start a new segment\n",
    "                \n",
    "#     # Add last segment if any\n",
    "#     if current_segment:\n",
    "#         segments.append(pd.DataFrame(current_segment))\n",
    "    \n",
    "#     return segments\n",
    "\n",
    "# movements = segment_movements(tongue_filtered, max_dropped_frames=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def segment_movements(df, max_dropped_frames=3):\n",
    "    segments = []\n",
    "    current_segment = []\n",
    "    nan_counter = 0\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        if pd.isna(row['x']) or pd.isna(row['y']):  # Object not detected\n",
    "            nan_counter += 1\n",
    "        else:  # Object detected\n",
    "            nan_counter = 0\n",
    "            \n",
    "        if nan_counter <= max_dropped_frames:  # Allowable dropped frames\n",
    "            current_segment.append(row)\n",
    "        else:\n",
    "            if current_segment:  # Save the current segment if not empty\n",
    "                segment_df = pd.DataFrame(current_segment)\n",
    "                \n",
    "                # Check if all values (except time) are NaN\n",
    "                if not segment_df[['x', 'y', 'xv', 'yv', 'v']].isna().all().all():\n",
    "                    # Trim only leading and trailing NaNs\n",
    "                    first_valid_idx = segment_df[['x', 'y']].notna().idxmax().min()\n",
    "                    last_valid_idx = segment_df[['x', 'y']].notna()[::-1].idxmax().min()\n",
    "                    trimmed_segment_df = segment_df.loc[first_valid_idx:last_valid_idx].reset_index(drop=True)\n",
    "                    \n",
    "                    segments.append(trimmed_segment_df)\n",
    "                \n",
    "                current_segment = []  # Start a new segment\n",
    "    \n",
    "    # Add last segment if any and trim it\n",
    "    if current_segment:\n",
    "        segment_df = pd.DataFrame(current_segment)\n",
    "        \n",
    "        if not segment_df[['x', 'y', 'xv', 'yv', 'v']].isna().all().all():\n",
    "            first_valid_idx = segment_df[['x', 'y']].notna().idxmax().min()\n",
    "            last_valid_idx = segment_df[['x', 'y']].notna()[::-1].idxmax().min()\n",
    "            trimmed_segment_df = segment_df.loc[first_valid_idx:last_valid_idx].reset_index(drop=True)\n",
    "            segments.append(trimmed_segment_df)\n",
    "    \n",
    "    return segments\n",
    "\n",
    "\n",
    "movements = segment_movements(tongue_filtered, max_dropped_frames=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_segmented_movements_global_time_colored(segments):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Find global minimum and maximum time for consistent color mapping\n",
    "    all_times = pd.concat([segment['time'] for segment in segments])\n",
    "    global_min_time = all_times.min()\n",
    "    global_max_time = all_times.max()\n",
    "\n",
    "    for i, segment in enumerate(segments):\n",
    "        if not segment['x'].empty:\n",
    "            # Normalize time based on the global min and max\n",
    "            norm_time = (segment['time'] - global_min_time) / (global_max_time - global_min_time)\n",
    "            norm_time = segment['time'] - segment['time'][0]\n",
    "            \n",
    "            # Mark start point of each segment\n",
    "            plt.scatter(segment['x'].iloc[0], segment['y'].iloc[0], c = norm_time[0], cmap='YlGnBu_r', s=20, alpha=0.8)\n",
    "\n",
    "            # Plot each segment with color gradient based on actual time\n",
    "            plt.scatter(segment['x'], segment['y'], c=norm_time, cmap='YlGnBu_r', s=5,alpha = 0.8)\n",
    "\n",
    "            \n",
    "    plt.xlabel('X Position')\n",
    "    plt.ylabel('Y Position')\n",
    "    plt.colorbar(label='Time (s)')\n",
    "    plt.title('Segmented Tongue Movements')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# Call plot_segmented_movements_global_time_colored on the list of segments from segment_movements function\n",
    "plot_segmented_movements_global_time_colored(movements[0:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to plot original and segmented data with a categorical colormap\n",
    "def plot_original_and_segmented_data(original_data, segments, xlim=None):\n",
    "    plt.figure(figsize=(20, 6))\n",
    "\n",
    "    # Plot original data\n",
    "    plt.scatter(original_data['time'], original_data['x'], color='gray', s=30, label='Original Data', alpha=0.5)\n",
    "\n",
    "    # Use 'tab20' colormap for distinct segment colors\n",
    "    colors = plt.cm.tab20(np.arange(len(segments)) % 20)  # Cycle colors if more than 20 segments\n",
    "\n",
    "    for i, segment in enumerate(segments):\n",
    "        plt.scatter(segment['time'], segment['x'], color=colors[i], s=10)\n",
    "    \n",
    "    # Labels and legend\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('x position (pix)')\n",
    "    plt.title('Original and Segmented Movements')\n",
    "    \n",
    "    if xlim is not None:\n",
    "        plt.xlim(xlim)\n",
    "    else:\n",
    "        plt.xlim([0, segments[-1]['time'].values[-1]])\n",
    "\n",
    "    plt.ylim([300,400])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Call plot_original_and_segmented_data with your original data and segments\n",
    "plot_original_and_segmented_data(tongue_masked, movements[0:70],[0,60])\n",
    "plot_original_and_segmented_data(tongue_masked, movements[0:70],[49,52])\n",
    "plot_original_and_segmented_data(tongue_masked, movements[0:70],[50,50.25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old kinematics filter that filtered all the position and velocity together. more principles to filter position sufficiently then derivative after filtering\n",
    "\n",
    "def kinematics_filter(df, frame_rate=500, cutoff_freq=20, filter_order=8):\n",
    "    \"\"\"\n",
    "    Applies interpolation and low-pass filtering to kinematic data to smooth trajectories and velocities.\n",
    "    \n",
    "    Parameters:\n",
    "    df : pandas.DataFrame\n",
    "        Input DataFrame containing time-series kinematic data with required columns: ['time', 'x', 'y'].\n",
    "    frame_rate : int, optional\n",
    "        Sampling frequency of the data in Hz (default is 500 Hz).\n",
    "    cutoff_freq : float, optional\n",
    "        Cutoff frequency for the low-pass Butterworth filter in Hz (default is 20 Hz).\n",
    "    filter_order : int, optional\n",
    "        Order of the Butterworth filter (default is 8).\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame\n",
    "        A DataFrame with interpolated and filtered kinematic data, including time, position (x, y),\n",
    "        velocity components (xv, yv), and speed (v).\n",
    "    \n",
    "    Notes:\n",
    "    - Interpolates missing data points to ensure evenly spaced timestamps.\n",
    "    - Computes velocity from positional changes over time.\n",
    "    - Applies a zero-phase low-pass Butterworth filter to smooth kinematic signals.\n",
    "    - Retains only the originally available (non-NaN) time points in the final output.\n",
    "    \"\"\"\n",
    "    # Ensure the DataFrame has the required columns\n",
    "    required_columns = ['time', 'x', 'y']\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(f\"Input DataFrame must contain the columns: {required_columns}\")\n",
    "    \n",
    "    # Generate new timestamps for interpolation\n",
    "    t = df['time'].values\n",
    "    dt = np.diff(t)\n",
    "    new_ts = []\n",
    "    for num in range(len(dt)):\n",
    "        tspace = dt[num] / (1 / frame_rate)\n",
    "        intgr = int(np.floor(tspace))\n",
    "        if intgr >= 2:\n",
    "            new_t = np.linspace(t[num], t[num + 1], intgr)\n",
    "            new_ts.extend(new_t)\n",
    "    new_t = np.unique(np.concatenate((t, new_ts)))\n",
    "    \n",
    "    # Interpolate missing data points\n",
    "    x_nonan = df['x'][df['x'].notna()].values\n",
    "    y_nonan = df['y'][df['y'].notna()].values\n",
    "    t_nonan = df['time'][df['x'].notna()].values\n",
    "    \n",
    "    x = np.interp(new_t, t_nonan, x_nonan)\n",
    "    y = np.interp(new_t, t_nonan, y_nonan)\n",
    "    intrp = pd.DataFrame({'time': new_t, 'x': x, 'y': y})\n",
    "    \n",
    "    # Compute velocity\n",
    "    times = intrp['time'].values\n",
    "    t_diff = np.gradient(times)\n",
    "    xv = np.gradient(intrp['x'].values) / t_diff\n",
    "    yv = np.gradient(intrp['y'].values) / t_diff\n",
    "    v = np.sqrt(xv**2 + yv**2)\n",
    "    \n",
    "    intrp['v'] = v\n",
    "    intrp['xv'] = xv\n",
    "    intrp['yv'] = yv\n",
    "    \n",
    "    # Apply low-pass Butterworth filter\n",
    "    cutoff = cutoff_freq / (frame_rate / 2)\n",
    "    b, a = butter(int(filter_order / 2), cutoff)  # Divide filter order by 2 for filtfilt\n",
    "    filtered_values = filtfilt(b, a, intrp[['x', 'y', 'v', 'xv', 'yv']].values, axis=0)\n",
    "    \n",
    "    filtered_df = pd.DataFrame(filtered_values, columns=['x', 'y', 'v', 'xv', 'yv'])\n",
    "    filtered_df.insert(0, 'time', intrp['time'].values)\n",
    "    \n",
    "    # Keep data only at original (non-NaN) timestamps\n",
    "    df_temp = df.reindex(columns=list(filtered_df.columns.tolist()))\n",
    "    df_nonan_index = df['time'][df['x'].notna()].index.tolist()\n",
    "    filtered_df_nonan_index = filtered_df[filtered_df['time'].isin(t_nonan)].index.tolist()\n",
    "    df_temp.iloc[df_nonan_index] = filtered_df.iloc[filtered_df_nonan_index]\n",
    "    \n",
    "    return df_temp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 time event  value\n",
      "0 2025-03-28 10:10:00     A   20.0\n",
      "1 2025-03-28 10:20:00     B   30.0\n",
      "2 2025-03-28 10:40:00     C    NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample time series data\n",
    "time_series = pd.DataFrame({'time': pd.to_datetime(['2025-03-28 10:00', '2025-03-28 10:15', '2025-03-28 10:30']), 'value': [10, 20, 30]})\n",
    "\n",
    "# Sample event data\n",
    "events = pd.DataFrame({'time': pd.to_datetime(['2025-03-28 10:10', '2025-03-28 10:20', '2025-03-28 10:40']), 'event': ['A', 'B', 'C']})\n",
    "\n",
    "# Merge using merge_asof\n",
    "merged_df = pd.merge_asof(events, time_series, on='time', direction='forward')\n",
    "\n",
    "print(merged_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
